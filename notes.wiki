 
 *Skupiamy się na wydajnym renderingu przezroczystości; Chcemy szybko zamknąć ten temat*
 
 czy jest sens bawic sie w vulkan teraz? docelowo i tak musoalbym to chyba zrobic, zeby
 bylo bardziej portowalne?
 - może lepiej nie, zrobmy najpierw cos dzialajacego i nie inwestujmy w to za duzo czasu!
 
*Simple 1280x1024 (full alpha)*
             normal  msaa4x  msaa16x
	 dragon:   900    1010    1100
   hairball:  5780    7380   14270
 powerplant: 13030   12540   19330
 san-miguel:  8590    9440   15790
	 sponza:  1700    1940    6390

*Stats 29.10*: total  setup  bins  tiles  raster_masks  sort_masks  final_raster
	 #boxes: 6334   25     54    136    487           1693        3513
	  bunny: 1989   48     48    96     388           487         720
 conference: 4497   94     95    251    693           1012        1788
	 dragon: 3474   309    134   217    638           737         910
	gallery: 7913   345    156   376    1326          2056        3321
   hairball: 25548  989    587   2589   11105         3834        5440
 powerplant: 31435  3873   1625  1774   10661         4854        8049
 san-miguel: 27837  2033   641   967    3821          5614        13651
  scrubPine: 2831   16     35    106    308           470         1501
	 sponza: 14820  167    167   358    1122          3221        9211
	 teapot: 2018   29     46    81     307           459         901
  white_oak: 11641  53     59    193    684           2705        7568

*Stats 02.11*: total  setup  bins  tiles  raster_masks  sort_masks  final_raster
	 #boxes: 5879   27     53    134    481           1751        3283
	  bunny: 1882   52     50    100    385           498         655
 conference: 4077   103    101   266    734           1148        1497
	 dragon: 3026   330    129   260    611           740         789
	gallery: 7564   365    152   424    1350          2127        2805
   hairball: 23023  1095   582   2423   9895          3839        4522
 powerplant: 31773  3595   1599  2390   10908         4862        6764
 san-miguel: 25494  2106   631   1289   3801          5613        11555
	 sponza: 13280  173    177   358    1101          3194        8074
	 teapot: 1857   33     46    80     302           456         815
  white_oak: 10781  56     60    186    671           2734        6923
 
*Stats 16.11*: total  setup  bins  tiles  raster_masks  final_raster
      bunny: 1975   104    48    89     1004          605
 conference: 3481   85     83    223    1697          1262
     dragon: 2858   299    128   249    1271          781
    gallery: 6494   386    147   401    2702          2708
   hairball: 39292  1023   577   2242   15445         19099
 powerplant: 32365  3800   1838  2340   11582         12317
 san-miguel: 23592  2028   627   1269   6263          13064
     sponza: 11420  164    160   330    3058          7549
     teapot: 1965   32     45    74     911           785
  white_oak: 9283   71     56    178    2252          6589
*Resolution:* (1280, 1024)

*Partial results (bins with > 1024 tris not rendered) (total time):*
     bunny: 1352
conference: 2604
 scrubPine: 1633
    sponza: 7426
    teapot: 1306
 white_oak: 19153

-----------------------------------------------------------------------------------------
                    === Rasteryzacja wszystkich sampli na raz ===
-----------------------------------------------------------------------------------------

* *TODO: drobne błędy wciąż widoczne na powerplant*

* *Problem: cały czas wolne samplowanie...*
  WhiteOak: 20ms vs 2.4ms ...
  
  Opcje:
  - Cieniowanie 2x2, 4x4, 8x8 ? 
  - Używanie SMEM do trzymania danych trójkąta ?
  - Jeszcze więcej wątków ?

* *Problem: będą też sytuacje gdzie sample nie będą poprawnie posortowane po zastosowaniu filtra*
  W takiej sytuacji będziemy musieli robić pełny sort? Będziemy musieli go w każdym razie
  lepiej zoptymalizować, żeby nie wykonywać aż tyle kroków; na pewno się da, tylko wymaga
  wysiłku
  Dodatkowo trzeba będzie generować głębokości;
  Problem: jeśli w s_bufferze będziemy mieli po 8 sampli na piksel, to nie zmieszczą się tam
  dane głębi...

  W takiej sytuacji generujemy sample od nowa?

* *Nie encoduj wielkości ekranu w shaderach: recompute przy resize*

* Trzymanie danych cieniowania dla każdego tróəkąta oddzielnie (i przeliczenie tego w setupie)
  trochę przyspiesza rasteryzację, ale nie dużo: 7.2 -> 6.54...
  A było to dla wszystkich trójkątów i nie licząc czasu na ich precompute-owanie...

* Iterowanie po tile-ach a nie po binach w raster_tile dla całej grupy tez nie pomaga (choć
  teoretycznie jest bardziej cache friendly...)

Inny pomysł:
-trzymanie razem danych wierzchołków w różnych buforach:
  uv+color+normal

Sceny:        frag/4x4    tris/4x4
Hairball:      1500        1000
Powerplant:     700         300
Sponza:         150         30
Dragon:          50         20

W przypadku hairballa możemy co najwyżej rasteryzować do 8x8 (i tak nie zawsze i przy 1024
wątkach), większe będą miały za dużo fragmentów.

Co możemy zrobić z dużymi ilościami trójkątów? Jeśli liczba fragmentów się zmieści, to nie
powinno być problemu? Po prostu nie wszystkie tróəkąty będą pre-computeowane?

* *Problem: jak mamy dużo tróəkątów na kafel to jest wolno*
  - w przypadku sponzy ta nowa strategia działa całkiem dobrze...

* *Problem: wolne cieniowanie*
  Jak to przyspieszyć? wiele pikseli z jednego trójkąta w ramach jednego wątku?
  - duże sample (4x) i małe sample?
  - co jeszcze możemy zrobić?
  - dla wybranych dużych tróəkątów ładujemy też parametry wierzchołków do SMEM?
    czy problem jest z ładowaniem czy obliczeniami?

  Dwu fazowy raster (najpierw generujemy głębokości + id trójkątów), sortujemy
  problem: jeśli będziemy rasteryzować posortowane sample, to stracimy na koherencji
  przy samplowaniu...

* Spawnujemy tyle wątków, żeby dało się zrenderować wszystkie sample do SMEM. Jeśli sampli
  jest za dużo na dany kafel, to zawężamy zakres pikseli (16x16, 8x8, 4x4).
  Np. 1024 wątki powinny pozwolić spokojnie na 2048 sampli.

* Najpierw musimy oszacować ile fragmentów mamy w każdym pikselu. Wyznaczamy też offsety
  dla każdego piksela.

* Teraz musimy równomiernie rozłożyć pracę cieniowania pomiędzy wątki. Jest kilka podejść:
  - Zaraz po wygenerowaniu masek dla trójkątów, bucketujemy maski wg. ilości fragmentów.
	Następnie każdy tróəkąt przydzielamy dla innego wątku. Taka metoda może dobrze działać jak
	mamy dużo tróəkątów i mało sampli na trójkąt.
	
  - Bardziej zbalansowana metoda: równomiernie rozdzielamy sample z trójkątów między wątki
	(sąsiednie wątki mogą pracować na tym samym trójkącie).
    - Prefix Sum po ilości sampli w trójkątach. A następnie każdy wątek znajduje swoje sample binarnie?
	  da się lepiej?
	  troszkę hierarchicznie: znajdujemy min/max indeks najpierw dla każdego warpa a następnie
	  w ramach warpów.
	  
	  Uwaga: jeśli mamy więcej niż dwa sample na wątek, to może się zdarzyć, że jeden wątek
	  obsługuje dwa trójkąty? TODO
      
	  Dla każdego wątka będziemy mieli przydział (id_trójkąta, id_sampla_w_trójkącie)
	  Jak wyznaczyć pozycję piksela ?

      Chyba, że najpierw bym wygenerował pozycje sampli w SMEM a następnie je po prostu
	  zgarniał?
	  
	  Generowanie pozycji:
	  - trójkąty są posortowane wg. ilości sampli (bucket sort); każdy wątek dostaje jeden
	    tróəkąt i iteruje po samplach...
		To jest słabe... czy da się lepiej?
	  - zależy od tego jaką mam reprezentację...
	  - TODO: do rozwiązania!
	  
* Następnie robimy cieniowanie. Każdy wątek teraz wie jaki cieniuje tróəkąt i w jakiej pozycji.
  Ale nie ma jeszcze danych trójkąta! Więc zanim zajmiemy się cieniowaniem, najpierw robimy triangle
  setup. Używamy do tego tego samego miejsca którego docelowo użyjemy do sampli. Zakładamy
  tutaj, że całe dane trójkątów się zmieszczą w SMEM. jeśli nie, to zawężamy...
  
  Na każdy trójkąt używamy jednego wątka: wyliczamy wszystko potrzebne do wyznaczania
  głębokości oraz współrzędnych barycentrycznych.
  
  Jeśli mielibyśmy też więcej miejsca (np. ilość trójkątów 2* mniejsza niż ilość miejsca)
  to robimy special case gdzie ładujemy też np. koordynaty UV, etc.
  
  Po załadowaniu tróəkątów do SMEM wszystkie wątki ładują odpowiadające im dane trójkąta do
  rejestrów. TODO: Zakładamy, że każdy wątek może obsługiwać max 1 trójkąt.
  Robimy synchronizację i w tym momencie dane trójkątów w SMEM nie są już potrzebne.

  Cieniujemy wszystkie sample i wrzucamy je do SMEM używając atomowych liczników per pixel
  (mogą być 16-bitowe).
  
* Mamy wygenerowane sample w SMEM, teraz musimy te sample w ramach każdego piksela.
  Dostępne opcje:
  - jakiś segmented sort (TODO: czy bitonic sort da się przerobić na taki?)
    bitonic sort musiałby działać tak, że w każdym wątku musimy wiedzieć, do jakiego segmentu
	należy aktualna i porównywana próbka. jeśli są różne to nic nie robimy?
    zrobienie tego na shuffle-ach może być problematyczne...
	na początek możemy zrobić bez shuffle-i
	
* Po posortowaniu musimy zmergować wszystkie sample w ramach każdego z pikseli. Robimy coś w
  rodzaju segmented reduce.
  
  Np. mamy sample S0, S1, S2, S3, ..., SN
  Chcemy wyliczyć:
  ( ... (Back.col * (1 - S0.a) + S0.col * S0.a) * (1 - S1.a) + S1.col * S1.a ...) * (1 - SN.a) + SN.col * SN.a

  Łączymy sample hierarchicznie, przy czym zamiast trzymać (Color, Alpha) lepiej trzymać:
   (Color * Alpha, 1 - Alpha), takie sample łatwiej się merguje:
   
   Merge(S0, S1) = (S0.premul_color * S1.neg_alpha + S1.premul_color, S0.neg_alpha * S1.neg_alpha)

   Robimy segmentowaną redukcję używając tej funkcji Merge. Tak samo jak z sortowaniem:
   mergujemy tylko jeśli sample należą do tego samego piksela.
   
   W samplach encodujemy pozycję piksela, czy każdy wątek z innego źródła wie który to piksel?
   - jak z innego źródła ? Z offsetów sampli per pixel ?
     Vectorized search od nvidii (pdf na lapku), ale na razie chyba po prostu każda próbka zajmie 40 bitów?

   - 24 bity na głębokość
   - 8 bitów na alphę
   - 11 + 11 + 10 bitów na RGB ? wystarczy? jeśli nie to możemy jeszcze z 8 bitów przeznaczyć? 13 + 14 + 13
   - 8 bitów na pozycję piksela
    Np. 2048 sampli: 8KB głębia + alpha, 8KB kolory, 2KB na pozycje piksela
  
  Po redukcji (bedzie tu pewnie trochę zabawy z wydajnymi dostępami do SMEM) zapisujemy
  wartości pikseli do Framebuffera i voila!
  
  Problem: MSAA! jak rozdzielić funkcję widoczności od cieniowania?

=== Pierwsza implementacja ===

- przerabiamy mask_raster:
  - wywalamy sort
  - generujemy maski (16x16) do scratcha, bez wyliczania głębokości!
    - na razie poo prostu generujmy 4 uinty i tyle!

  - jak szybko zliczyć sample w pikselach?
    - tablica +1 / -1
	- na końcu prefix sum? 2 rzędy liczymy równocześnie (16-bitów)

  - na początek tylko wyświetlanie ilości pikseli, nic więcej



-----------------------------------------------------------------------------------------
                                      === Różne ===
-----------------------------------------------------------------------------------------

*Nowy pomysł !!!*
- rendering wszystkich sampli na raz
  (możemy renderować cały tile jeśli się zmieszczą, jeśli nie to bloki 8x8 albo 4x4).
- wrzucamy wszystkie sample do SMEM
- sortujemy i robimy redukcję po pikselach (segmentowana?)
  Problem: nawet jeśli sample się zmieszczą w SMEM to tróəkąty już nie muszą.
  nie mogę też zająć całego miejsca w SMEM samplami pewnie

  Jeśli trójkąty byłyby posortowane wg. ilości sampli (można by je pobinować)
  to generacja mogłaby być całkiem szybka?



  Problem by był tylko jeśli mielibyśmy np. bardzo mało tróəkątów per bin, ale taką sytuację
  BARDZO ŁATWO można obsłużyć prostszym algorytmem!


*Sortowanie niektórych trójkątów per tile a niektórych per blok; a potem mergowanie ich?*

* Po fazie binowania może lepiej by było nie generować wszystkich danych, ale używać scratcha,
  od generacji indeksów trójkątów per tile aż do finalnej rasteryzacji. Tym sposobem można by
  mocno ograniczyć zużycie pamięci a może też ilość operacji na pamięci (ale raczej tylko w
  przypadku małych binów).


*Binowanie tróəkątów w tile-ach po ilości linii a następnie generowanie linii dla całego tile-a od razu*
- tam gdzie wiemy że będzie <= 4, 8, 12 linii możemy użyć mniej uintów do zapisania masek

*Potrzebujemy różnych strategii na różne sytuacje!*

warstwy są na zmianę? w aktualnym algo to nie jest proste: iteruję po maskach i testuję bity...
iteracja po co drugiej warstwie?

Co mi to da oprócz dodatkowego skomplikowania? Będzie trzeba załadowac 2x tyle tróəkątów i
tak...

-----------------------------------------------------------------------------------------
                             === Nowa finalna rasteryzacja ===
-----------------------------------------------------------------------------------------

- Odpinamy wątki od pixeli
- framebuffer trzymamy w SMEM (może być w częściach)

Problem: jak wątki zapisują sample do framebuffera w SMEM, to co robić z kolizjami?
  atomowo tej operacji nie zrobię, bo jest skomplikowana...
  DUPA!!!
  
  W jakiś sposób pakować więcej wątków per pixel i później serializować wyniki?
  Dzięki temu będzie można lepiej współdzielić dane tróəkątów, a sam commit do framebuffera
  powinien być szybki?
  
  
  Jak zrobić szybki commit z dużej liczby wątków do wspólnego Framebuffera?
  A może z większą liczbą wątków mógłbym łatwiej trzymać wszystkie trójkąty w SMEM?
  Np. 512 trójkątów od razu? Bloki z małą liczbą tróəkątów bym załatwiał małymi kernelami?

  Musiałbym tylko zapewnić poprawną kolejność! Ale jak to wymusić na tak dużej liczbie wątków?
  
  Najpierw wszystkie wątki rasteryzują 4 piksele powiedzmy a potem jest commit po wszystkich w
  odpowiedniej kolejności.
  
  Problem: jeśli są duże różnice w ilości pikseli per trójkąt, to wątków musi być co najmniej
  kilka razy mniej niż tróəkątów, inaczej niektóre skończą wcześniej i będą czekać.
  
  To oznacza, że muszę być w stanie dzielić pojedyncze trójkąty między wątki...
  
  W takim razie może trzymajmy trójkąty w SMEM? Jeśli możemy zaalokować więcej wątków, to mamy
  też więcej miejsca na trójkąty?
  
  Ale musielibyśmy być w stanie załadować wszystkie tróəkąty? 512 wątków 384 tróəkąty?
  Początkowo 256 wątków na blok? 
  
  
  OK ale muszę wykminić jak zrobić commitowanie...
  
  Wątek który ma próbkę do zacommitowania musiałby czekać aż wszystkie próbki przed nim w danym
  pikselu zostały zacommitowane.
  
  
  
Alternatywny pomysł: mergowanie masek. Do tego jest potrzebne jedynie wyliczenie głębokości.
- nie potrzebowalibyśmy filtra głębokości na koniec, musielibyśmy tylko wykrywać sytuację gdy
- głębia jest niepoprawna (dałoby się zrobić atomowo na u64?)

Tworzylibyśmy warstwy bezpośrednio do przetworzenia dla rasteryzera, w takiej sytuacji każda
warstwa mołgaby mieć inną reprezentację? (reprezentacje musiałyby być takie same w ramach 8x8)

Problem: indeksy trójkątów. Dla każdej warstwy mamy inny zestaw indeksów trójkątów?
  - offset do indeksów, ilość trójkątów, ilość bitów na indeks w masce.
Problem: kto ładuje które trójkąty?

Problem: co jeśli mamy 64 trójkąty w masce?
  - zależnie od ilości tróəkątów rózne strategie? musiałyby być wspólne dla bloku 8x8!
  - poza tym, co jak mam 4 trójkąty? 28 wątków czeka?

Dobrze by było żebyśmy mogli współdzielić tróəkąty między warstwami. Mielibyśmy dwa strumienie:
- strumień trójkątów, i strumień warstw.
W każdym kroku dochodzi trochę nowych trójkątów a trochę wypada.
Indeksy w warstwie mapują się na tróəkąty z drugiego strumienia.

Jest jakiś limit trójkątów w SMEM. Pewnie więcej niż 48 / 64 wątki nie zmieszczę...

Problem: jak generować takie strumienie?



Może najlepiej by było jakby wątek który ładuje trójkąta zajmował się też renderingiem jego
pikseli? SMEM by było użyte do trzymania framebuffera.
- jeśli mielibyśmy dane posortowane per pixel, podzielone na warstwy i równomiernie rozłożone
- w paczkach.
- moglibyśmy trzymać 4 piksele na wątek (głębię + kolor)

To też jest słabo, bo często się zdarza, że cały blok (16 pikseli) jest wypełniony  jednym
trójkątem. W takiej sytuacji 4 razy bym ładował dany trójkąt. A na jeszcze szerszy kontekst
mnie nie stać (16 pikseli na wątek).



Czy da się jakoś zrobić mechanizm synchronizacji sampli z różnich warstw generowanych przez
różne wątki?

Np. mam grupę 4x4 piksele. Zaalokowałem do niej 8 wątków. 4 wątki pracują na warstwie 0, 4 na
warstwie 1. 
Czy na róznych warstwach powinny pracować różne warpy? Warstwa N może być zmergowana dopiero
jak warstwa N-1 jest zmergowana w całości. Tylko, że wątki zanim zmergują mają trzymać sample w
rejestrach?


To może inaczej:
- dane tróəkątów w SMEM. po jednym warpie na warstwę. Np. 512 wątków na blok 8x8. Od razu
  ładujemy wszystkie trójkąty.
  Generujemy sample (wątek w każdym warpie odpowiedzialny za max 2 piksele?). 
  Na końcu warpy w kolejności commitują wygenerowane sample do Framebuffera w SMEM.
  
  Dzięki temu, triangle setup robimy tylko raz na tróəkąt.
  Dobrze by było maksymalnie jak się da upakować warstwy.
  Problem: jak równomiernie rozkładać pracę nad pikselami między wątki?


Problem: jak dobrze zrobić algorytm generowania upakowanych warstw?
- jest to na pewno prostsze niż pełna rasteryzacja
- na inpucie mamy to co teraz generuje mask_raster, tylko posortowane?
  może być dużo pustych pikseli, chodzi o to żeby po nich nie iterować

mergowanie hierarchiczne?
- 

problemem aktualnie jest faza finalna i faza sortowania, na tych etapach raczej podział
trójkąty na duże/małe/particle nie ma sensu?


Jak zrobić warstwy?
Powiedzmy, że na razie chcemy jedynie przyspieszyć sortowanie i na razie robimy 4x4.
- w ramach warstwy znowu mamy sytuację gdy trójkąty mogą być duże lub małe; jak by były duże to
  możemy rozpatrywać same trójkąty
- mielibyśmy dwie ścieżki? jedna ścieżka dla małych meshletów i druga dla całych trójkątów?
  przed sortowaniem mergowalibyśmy je w jeden strumień
  jeden strumień czego?
  dla zwykłego trójkąta: 16-bit indeks w liście tile-i
  dla warstwy: indeks meshleta + 16 * 4 bity w każdym pikselu
    problem: taka reprezentacja w finalnym rasteryzerze jest taka sobie

  jeśli za dużo będę przechowywał per-piksel to może się bardziej opłacać po prostu przechować
  kolor + głębię (64-bity). Minus jest taki, że nie działa efekt mgły
  Jeśli za dużo danych przechowuję per trójkąt i mam średnio 1 trójkąt na piksel, to może się
  to bardziej opłacać...

  Teraz w przypadku masek mam 32-bity na maskę i mały indeks + 32-bity na indeks w tile-u +
  32-bity na indeks w binie...
  Choć to jest przypadek krańcowy... średnio tróəkąt ma pewnie z 2-3 piksele...


  Może mógłbym utrzymać założenie, że w jednym bloku jest jedna warstwa?
  jeśli dwie warstwy się ze sobą przecinają, to mógłbym jedną z nich rozbijać na dwie?
  Ale jak to dobrze robić?

  Obawiam się, że warstwy oparte o meshlety na końcu mi się nie przydadzą: W ramach bloku
  potrzebuję minimalnej listy tróəkątów które faktycznie występują na danym bloku

  jeśli byłbym w stanie podzielić tróəkąty w ramach tile-a na niezależne segmenty to mógłbym
  jakoś zawęzić liczbę tróəkątów?
  
  Tyle, że indeksy trzymam per- tile a nie per blok. Per blok byłoby więcej?
 
 
  Przy rasteryzacji chcę jak najszerszy kontekst? nie koniecznie, bo np. w hairballu max trisów
  na tile to > 64K...

  Problem z równoległym obliczaniem różnych warstw: nie mam dostępu do wartości piksela pod
  spodem...
  
  Tak naprawdę to ten efekt mgły jest dośc ograniczony, jeśli mam tylko wartość koloru. Może
  fajnie by było mieć indeks trójkąta np. ?

  Kompromis: 4 wątki na blok (każdy wątek obsługuje inny rząd)?
- Ale, żeby mieć 4 piksele na wątek, to muszę mieć post-sortowane warstwy!

  Jaka jest najsensowniejsza reprezentacja dla warstwy?


-----------------------------------------------------------------------------------------
                          === Problemy z aktualnym systemem ===
-----------------------------------------------------------------------------------------

* Rendering transparencji wymaga renderowania trójkątów w odpowiedniej kolejności; uniemożliwia
  to sortowania tróəkątów po materiałach i raczej wymaga stosowania uber-shadera

* Duże straty na wydajności przy rysowaniu sliverów (najlepiej widoczne na hairballu). Wynika
  to przede wszystkim z tego, że faktyczną rasteryzcję wykonuję dopiero na etapie bloków,
  wcześniej (na etapie binów i tile-i) używam jedynie AABB.

* Filtrowanie głębokości wymaga skwantyzowania koloru do 8-bitów na komponent. Może to
  powodować problemy i prawdopodobnie muszę w takiej sytuacji robić za każdym razem konwersję
  do/z sRGB. Ew. mógłbym przeznaczyć więcej bitów na kolory (10/11) a wartość alpha trzymać
  razem z głębokością (zmniejszoną do 24 bitów).

* Kafle mogą aktualnie obsłużyć max 64K trójkąty; Na niektórych scenach to za mało (San Miguel)
  Dodatkowo nie obsługujemy na razie kafli gdzie ilość trójkątów w blokach jest większa niż 2K.

* Główne etapy pipeline-u są cału czas zbyt wolne:
  - generowanie masek
  - sortowanie masek
  - finalna rasteryzacja

* *Podstawowy problem: przechowywanie danych trójkątów w SMEM*
  Generalnie jeden wątek operuje na 1 trójkącie, a 1 tróəkąt wymaga dużo danych!
  Jeśli dałoby się obliczenia wykonywać na 16-bitach, to by nie było problemów?
  Ale raczej się nie da...


* *Mam limit na trójkąty per tile: 64K; ale na hairballu jest przekraczany...*

-----------------------------------------------------------------------------------------
                 === Potencjalne rozwiązania / ulepszenia algorytmu ===
-----------------------------------------------------------------------------------------

* *Dodać opcję wizualizacji głębokości do głównego menu (bez rekompilacji)*

* *Bucketowanie trójkątów w tile-ach po ilości rzędów*
  Najlepiej by było brać pod uwagę wygenerowane maski, ale nie mamy ich na etapie estymacji
  Na etapie estymacji mamy jedynie wymiary quadów w tile-ach. Możemy zrobić 4 albo 16 bucketów.
  To powinno poprawić dystrybucję trójkątów na etapie 
  Problem jest taki, że nie jestem w stanie z wyprzedzeniem wyliczyć ile trójkątów będzie w
  każdym z bucketów, bo niektóre mogą być zcullowane.

* *4x4 może sie okazać zbyt kosztowne* Może zrobić tylko opcję 8x8?

* *Nowy algorytm rasteryzacji finalnej*
  - alokujemy 64 wątki na kafel; W danym momencie mogą przetwarzać max 64 piksele na raz
  - wątek jak przetwarza piksel to robi to od początku do końca, ale jak skończy to może
	przejść do następnego
  - ładujemy na początek tróəkąty z max 4 bloków do 4 różnych slotów. W momencie w jakim
	załadowaliśmy już wszystkie trójkąty dla danego bloku i jakieś tróəkąty zostały
	przetworzone, możemy ładować tróəkąty z kolejnego, jeszcze nie przetwarzanego bloku.
	W efekcie w danym slocie w danym momencie mogą być tróəkąty z 2 różnych bloków.
	Dla każdego bloku śledzimy:
	- ilość całkowicie przetworzonych trójkątów
	- ilość załadowanych tróəkątów
	- wskaźnik na najwcześniej załadowany trójkąt; w momencie w jakim trójkąt jest przetworzony
	  ten wskaźnik się przesuwa do przodu i zwalnia miejsce na tróəkąty dla kolejnego bloku
  Problem: efektywna implementacja

* *Encodowanie danych trójkąta?*
  - wektory normalne można zakodować jako 1 liczba 32-bitowa
    ale z długościami już by było gorzej
    Czyli teoretycznie wektor możemy zakodować w 64-bitach zamiast w 96?
    Całkiem dobrze można zakodować normalną w 32 bitach (metoda hemi oct)
    tri0: 3xf32, edge0: f32+u32, edge1: f32+u32 (7 liczb i tak...)

* *Lepszy load balancing*
  - W różnych fazach możemy po załadowaniu trójkątów jakoś je pogrupować, żeby zmniejszyć
    rozbierzność w ramach wątków
  - W niektórych fazach zmiana ilości wątków w grupie mocno wpływa na wydajność w danej scenie.
	Dla różnych scen różne wartości sa optymalne. Może dałoby się tak przerobić te algorytmy,
	żeby się w jakiś sposób same dopasowywały do danych?
	Np. tile dispatcher mógłby operować na więcej niż jednym binie na raz? Albo alternatywnie
	moglibyśmy mieć kilka tile-dispatcherów gdzie każdy ma inną ilość wątków w grupie i każdy
	by odpowiadał za biny o różnych ilościach tróəkątów.
  
* *Lepszy sposób zapisania danych warstwowych per-blok*
  Zamiast bit-masek dla każdego trójkąta moglibyśmy mieć:
  tablicę 4/6/8 bitowych indeksów + listę trójkątów
  Na hairballu to mogłoby dać duży zysk, ale  drugiej strony na sponzie nie bardzo...

* *Zamiast masek bitowych zapisujmy zakresy pikseli*
  - przeliczanie centroid: może da się szybciej
  - przerobić mask_raster: to chyba wymaga precompute-owanych normalnych...

* *Rendering niektórych binów w blokach 8x8 a nie 4x4*
  - każdy bin musiałby byc oznaczony jako 4x4 albo 8x8. Na razie chyba po prostu po ilości
	trójkątów? później jak dodamy specjalny path dla małych trójkątów, to ich ilość może
	bardziej wpływać na wybranie wersji 4x4 niż 8x8
  - możliwe też, że jeśli wersja 8x8 będzie dużo szybsza to wogóle zrezygnujemy z 4x4
 
  - nowy tile dispatcher: zaczyna z listą trójkątów w binie i generuje listy dla każdego
	sub-tile-a (8x8). Każdy sub-tile testujemy trivial rejectem & acceptem.
  - nowy mask raster: przechodzimy po listach i generujemy maski 8x8
  - nowy mask sorter: sortujemy każdą grupę niezależnie?
  - nowy tile_dispatcher: 
  To by wymagało:
  - nowa faza tile_dispatchera: od razu byśmy dispatchowali do sub-tile-i 8x8
  - nowa faza mask_rastera:     

* *Przyspieszenie sortowania*
  - może nie ma sensu sortować wszystkich bloków w tile-u razem? Lepiej chyba niezależnie?
  - razem ma sens jeśli liczba t©ójkątów jest naprawdę mała
  - Wersje sortera:
    <= 256  tri-bloków / kafel: sortujemy wszystkie razem
    <= 1024 tri-bloków / kafel: sortujemy wszystkie razem
	mask_raster od razu może posortować wg. bloków jeśli wszystkie się mieszczą w SMEM
	jeśli używamy scratcha to zawsze sortujemy każdy blok niezależnie
  - Alternatywnie te trójkąty moglibyśmy od razu posortować w mask_rasterze. I tak nie używamy
	w nim SMEMu.

	<=   64 tri / blok
	<=  256 tri / blok
	<= 1024 tri / blok
	>  1024 tri / blok
	Ale musielibyśmy też mieć bardzo szybką metodę iterowania po binach i ich kaflach

  Jak już zrobimy różne wersje, to można się pokusić o przyspieszenie na NVIDII za pomocą
  shuffli.

* *Finalny raster: Precompute-owanie danych dla trójkątów w ramach bloków w SMEM*
  Może dałoby się trzymać więcej danych, jeśli byśmy byli w stanie jakoś
  cache-ować wierzchołki?
  
  Specjalna obsługa tróəkątów które zajmują cały quad 4x4? W przypadku 4x4 jest ciężko, łatwiej
  by było to zrobić przy 8x8, bo wtedy robimy dla całego warpa.
  Moglibyśmy zrobić dwa rodzaje binów: w jednych operowalibyśmy na blokach 4x4 a w drugich na
  sub-tile-ach 8x8. Ale na jakiej podstawie stwierdzić która strategia jest lepsza w danym
  binie?
  Tam gdzie mielibyśmy odpowiednio gęstą geometrię byśmy szli 4x4. Bierzemy pod uwagę: ilość
  trójkątów, średnia wielkość tróəkąta i jego 'sliverowatość'. Ważne jest też czy tróəkąty są
  'skupione' czy rozrzucone, a właściwie, jak bardzo się przecinają. Ale tego się nie da szybko
  zmierzyć?
  
  Stosunek ilości trisów/blok do unikalnych trisów/tile:
  Dragon:1.07, SanMiguel:1.8, Sponza:4, Powerpl:2, Teapot:3, Hairball:1.5 Gallery:1.3 Conf:4
  
  Czy da się jakoś lepiej ładować tróəkąty? może jakoś zahashować? Ale co w wypadku kolizji?
  Ładować różne ilości masek, zależnie od tego, ile tróəkątów się mieści w buforze?

  Problem: nawet na Sponzie średnia ilość pikseli w masce to 10/16. Jeśli przyspieszymy 2x
  poprzez rysowanie wszystkich pikseli w ramach bloku dla danego trójkąta to stracimy prawie
  całe przyspieszenie przez rysowanie pikseli które są wyłączone.
  
  A co można zrobić ze scenami typu hairball? Jeszcze większy podział (2x2)? I przetwarzanie
  list 2x2 jedna za drugą. W tile-u mielibyśmy ich 64. Możemy przydzielić 32 wątki na kafel?
  Przy czym, po skończeniu każdego kawałka 2x2 od razu go zapisujemy do pamięci. Dzięki temu
  nie musimy trzymać w pamięci wszystkich pikseli, ale możemy lepiej zbalansować obliczenia?
  Grunt, żeby po jednej fazie cieniowania można było się szybko przełączyć na inną grupę 2x2.


* *Optymalizacja ładowania danych trójkątów do wczesnej rasteryzacji*
  - Współrzędne wierzchołków NDC można zapisać z 8-bitową sub-pixelową precyzją w 4 uintach
	(dla małych trójkątów mniej). To wszystko co potrzebujemy do rasteryzacji za pomocą
	algorytmu bazującego na liniach.
  - Do generowania głębokości wystarczy wektor normalny + plane_dist. To można zapisać w 3
	floatach.
  Obydwie te rzeczy można by precompute-ować w trans_setup: zapisanie 4 floatów/trójkąt zajmuje
  ok. 700msec na power plancie, 200msec na san miguel.
  
  W końcowej rasteryzacji te dane raczej się nie przydadzą, bo do wyznaczenia współrzędnych
  barycentrycznych potrzebujemy pełną informację o tróəkącie (minimum 9 liczb). Dałoby się
  wyliczyć z wierzchołków NDC i płaszczyzny wektory do wyznaczania barycentryków, ale to jest
  raczej niepotrzebne zawracanie dupy (szybciej będzie po prostu wczytać pozycje wierzchołków).

* *Przetwarzanie małych (max 8x8 pikseli) i dużych trójkątów niezależnie*
  - Dla małych trójkątów możemy w jednym kroku wyznaczyć maskę, a nie w każdym kaflu w jakim
	występuje. Moglibyśmy takie t©óəkąty binować wg. ilości zajmowanych rzędów, dzięki temu
	można by te maski bardzo wydajnie generować.
  - Dla dużych trójkątów dużo bardziej opłaca się sprawdzanie czy przecinają się z binem czy
	tile-em. W niektórych scenach wykonywanie takich testów powinno dać duży zysk (hairball).
	Jeśli wydzielimy małe tróəkąty to strata na pozostałych scenach powinna być bardzo mała (bo
	głównie dla małych tróəkątów ten test jest mało przydatny).
  - Problemem może być wyznaczanie wartości głębokości. Jeśli wyznaczę jedną wartość dla całego
	tróəkąta, to może to generować dużo niepoprawnych pikseli. Może jestem w stanie łatwo
	zidentyfikować takie problematyczne trójkąty? Po wektorze normalnym? Jeśli tróəkąt jest
	prawie prostopadły do promienia to będzie powodować problemy...

* *Optymalizacja trans_setup*
  Powinniśmy generować listę widocznych trójkątów; Setup po wstępnym przetworzeniu tróəkątów
  zapisuje dane / indeksy do SMEM i w kolejnej fazie kontunuuje przetwarzanie tylko na
  widocznych trójkątach/quadach.
  Problem: dane trójkątów nie mają szans zmieścić się w SMEM...

* *Przyspieszyć mip-mapping*
  - na razie w każdym pikselu efektywnie liczymy 3x zinterpolowane współrzędne UV i liczymy
	różnicę. Może dałoby się to zrobić jakoś szybciej? Np. wymuszając rendering w grupach 2x2?
	Coś mi się zdaje że będzie wolniej...

* *Meshlety*
  Oprócze tego, że zwiększyły by lokalność danych to moglibyśmy dzięki nim zrobić efektywnie
  precompute-owane dane.
  W meshletach oprócz wierzchołków i tróəkątów moglibyśmy też mieć krawędzie, które moglibyśmy
  precompute-ować (dla całego meshleta). Krawędzie byłyby współdzielone między trójkątami więc
  musielibyśmy wziąć pod uwagę kwestię kierunku.

* *Szybsze obliczanie małych sum prefiksowych*

* *Bug jeśli dwie powierzchnie na siebie prawie nachodzą (jedna backface)*
  szczególnie widoczne na sponzie

* *Bugi na Haswellu pojawiające się gdy jest za mała liczba wątków w mask_raster*

* *Bugi widoczne w różnych miejscach na powerplant jak się wyłączy backfaceculling*
  Czasami też widać miganie na rurach (pewnie są identyczne wartości głębi)

* Lepsze cache-owanie danych wierzchołków w finalnym rasterze? Ale jak to zrobić sensownie...

* Lepsza kolejność danych wejściowych: może to mocno wpływać na wydajność początkowych etapów
  pipeline-a (setup & binning).

* *Czy bardziej się opłaca rasteryzacja 3D czy 2D?*
  - w 2D musielibyśmy przechować pozycje wierzchołków i je poprzycinać;
    ale za to rasteryzacja byłaby prostsza? tak samo jak wyznaczanie bboxa dla trójkątów
	przyciętych w ramach kafla.

* *Option not to run checks every frame*

-----------------------------------------------------------------------------------------
                       === Dodatkowe ulepszenia aplikacji ===
-----------------------------------------------------------------------------------------

* Wymyślić jakąś nazwę dla algorytmu. Np. CBTR ? compute-based transparent rasterization ?

* Zaimplementować MSAA, zobaczyć czy tile-renderer ma przewagę nad hardwarem w tym zakresie.

* Dodać jakąś prostą animaowaną scenę? animowane boxy?

* Dodać możliwość renderingu obiektów nie-przezroczystych normalnie a jedynie przezroczystych
  za pomocą trans-renderera. To wymaga dodania obsługi czytania z bufora głębokości.

* Dodać weighted-blended OIT, żeby mieć porównanie z faktycznie stosowanym algorytmem?

* Dodać obsługę renderingu dwu-fazowego transparencji (od Wolfire):
  - materiały bez alphy najpierw, te z alphą potem
  - opcja: alpha test na 100% najpierw
  - sposób blendowania: normalny albo addytywny
    można tej metody użyć też razem z trans rendererem!

* Obsługa kamery orbitującej jest do D; dać możliwość focusowania się na klikniętym elemencie?

* Modyfikacja kawałków shaderów nie powoduje reloadu

* Rendering pół na pól (simple po lewej / trans po prawej).

----------------------------------------------------------------------------------------
                                    === Tri patche ===
-----------------------------------------------------------------------------------------

Dałoby się zrobić część meshy na quadach a część na tróəkątach?
Problemz ogólnym systemem: instancing...: dla każdej instancji muszę
przekształcić wierzchołki i je gdzieś zapisać, inaczej musiałbym to robić 2 razy:
- przy wyliczaniu AABB i podczas rasteryzacji (słabe); OK! akceptujemy to!

dobra, powiedzmy ze da się w miarę sensownie przerobić mesh bazujący na tróəkątach na quadowy.
Co dalej?
Grupować quady w czwórki ? Tylko takie które współdzielą wierzchołki?

Przy czym grupowanie w czwórki powinno być maksymalnie szybkim algorytmem. 
To czemu od razu nie robić ray-tracingu ? Może ne wszystko na raz

Ale Do grupowania obiektów mógłbym użyć grida albo BVH czy coś podobnego?
Musi to być szybkie. Przy czym mi zależy na tym, żeby przyspieszyć etap
rasteryzacji kafli i bloków. Jak zrobie quady, to pozostałe etapy powinny być wystarczająco
szybkie.

Grupowanie quadów w czwórki pomoże? Potencjalne problemy:
- więcej trójkątów do przetworzenia na poziomie tile-a?


Podobny algorytm można zrobić do generowania czwórek. Ale tutaj straty na pewno będą większe.
Co w takich sytuacjach? Czwórki będziemy rozpakowywać na poziomie tile-a?

Tak czy inaczej: najpierw powinniśmy zrobić same quady, jeśli przyspieszą to wtedy pomyślimy od
rozszerzeniu

Jaka byłaby reprezentacja takiej czwórki?
- 9 indeksów wierzchołków ?
- a co zrobić ze ścinkami?

Może coś prostszego: jakoś uporządkować quady? ale jak to zrobić szybko?
grupujemy jedynie quady które są faktycznie blisko siebie? Ale co będziemy robili z
nie=pełnymi grupami? Będą nam psuć occupancy!


A może dużo większe meshlety ? 256 wierzchołków i 512 trójkątów ?

32 wierzchołki: wystarczy 15 bitów na trójkąt


Generacja:
- ciągłość powierzchni nie jest taka ważna jak lokalność w przestrzeni?
- np. hairball: nie ma sensu lecieć po włosach, lepiej robić wycinki lokalnej przestrzeni

- do pewnego stopnia na pewno chcemy łapać trójkąty które są ciągłe
  A może: olać ciągłość, wybierać wierzchołki w pierwszej kolejności?


- Niezależnie trzymamy dane indeksów i wierzchołków ?
- Jakie limity ?

- Czy mogę zapewnić, że paczki wierzchołków/trójkątów będą wypełnione po brzegi?
- stosunek num_tris/num_verts wacha się od 0.8 do 2.1; Generalnie tróəkątów jest tyle co
  wierzchołków, a w niektórych meshach nawet 2x tyle


- Póżniej mozemy zdecydowac czy dopychamy trojkaty czy wierzcholki

- Na początek robimy to statycznie:
  - mamy listę instancji, każda instancja ma odnośnik do paczki trójkątów i jej wielkość?
    najprościej żeby paczki trójkątów miały takie same wielkości
    Może się okazać, że marnujemy pamięć, bo albo w buforze wierzchołków albo w buf. trójkątów
	będzie trochę zmarnowanego miejsca;
	Lepiej marnowac miejsce w buforze tróəkątów?

    - paczki po 64 wierzchołki; Instancja może mieć odnośnik do max 4 paczek (wierzchołki 0-63,
	  64-127, 128-191, 192-255).
	- Trójkątów ładujemy od razu 256?

	- Ilośc wierzchołków ustalamy na wartośc stałą a t©óəkątów na zmmienną?
	  Czy jest sens mieć więcej niż 256 tróəkątów?

	Czy mogę założyć, że w trans_setup będę miał więcej niż 1 meshlet?
  - Np. jeśli jeden się nie zmieścił to dopycham drugim?

	Wierzchołki:
	128 * float = 42 * float3 (position, normals, uvs + colors)
    256 * float = 85 * float3

	Trójkąty:
	64 * uint  = 85 trójkątów
    128 * uint = 170 trójkątów
  - 7 bitów na indeks: 64-bity = 3 trójkąty: 128 * uint = 192 trójkąty

	ChunkMeshInstance {
		u8 num_tris, num_verts;
		u16 flags; // has_uvs?, has_normals?, etc.
	    u32 verts_offset, uvs_offset, normals_offset;
  	 	u32 tris_offset;
		// Do tego: bounding boxy, zakresy normalnych (do szybkiego backface-cullingu)
  	 	// Parametry materiałów; Na razie po prostu jeden materiał na 1 chunk
	};

	Instancja: ~128 bajtów
	Tróəkąty:   512 bajtów
	Pozycje wierzchołków: 1024 bajty 
	UVki + kolory:        1024 bajty
	normalne:             1024 bajty

*Co trzeba zrobic?*
- wygenerować w miarę dobrze upakowane tri patche
- na razie olewamy bboxy? tak, żeby można było zrobić w miarę sprawiedliwe porównanie z podstawowym renderingiem
- skopiować TriPatche do pamięci GPU
- Przerobić tri_setup: dane wierzchołków (co najmniej pozycje) trzymamy w SMEM?
- Problem: gdzie trzymamy dane przycętych wierzchołków? Normalnie np. UVki wogóle nie są
  modyfikowane; Wraca dylemat: rastaryzacja 2D czy 3D ?
  Bez sensu przepisywać cały bufor jeśli zmienił się jeden wierzchołek
- W headerze trzymamy offset do bufora clipowanych wierzchołków; Najwyższy bit w wierzchołku
  oznacza, że jest clipnięty i tyle
- Inna numeracja trójkątów /  wierzchołków: Dla danego t©óəkąta mamy indeks paczki który
  identyfikuje od razu zestaw wierzchołków? A UVki i normalne?


Na początek najprostszy sposób:
- cała scena ma jeden rodzaj wierzchołka?  Jeśli byłyby różne typy, to w raster musiałbym mieć
  cache na instancje? Każdy dostęp do trójkąta wymaga odwołania do danych instancji?

  Chyba, że dane wierzchołków różnych typów byśmy trzymali w jednym buforze i po prostu miałyby
  rózne zakresy?

  Jak tróəkąt jest zapisany na liście w tile-u? 24-bit: indeks instancji + 8-bitów na indeks trójkąta?
  Na początek tak.

  Tile dispatch zajmuje dużo czasu, czy dałoby się to jakoś przyspieszyć? Przy pierwszym
  binowaniu możemy operować na instancjach (ew. z mapą bitową trójkątów). Powinno się dać coś
  przyspieszyć Np. jeśli dałoby się operować na grupkach (2-8) tróəkątów a nie całych tróəkątach
  to już moglibyśmy mieć duży zysk na tym etapie
  
Jak duże powinny być TriPatche? 
- na tyle duże, żeby wypełnić warp
- jak duże będą za duże? raczej na pewno będą za duże, żeby założyć, że większość trójkątów
  wypełnia kafel 16^2
  
--- *Cieniowanie* ---
- musimy przekazywać jakoś wektory normalne; Jak to robić najlepiej ?
  raczej nie ma sensu pakować wszystkiego do TriangleData. W triangle data zostawiamy indeksy
  wierzchołków, które są w jednym buforze wierzchołków
  Jak je indeksować ? 

  informacje jakie musimy mieć:
  - lista instancji: każda instancja ma indeks mesha, materiał, macierz, etc.
  - lista wierzchołków wejściowych;

  Problem: dane wierzchołków trzymamy w jednym dużym buforze? Oddzielne bufory na oddzielne
  atrybuty; każda instancja może mieć offset na globalny bufor wierchołków, normalnych,
  indeksów trójkątów, etc. ?

  W Trans nie muszę robić nic wyszukanego: mogę użyć alokatora BestFit


  - nie robimy żadnego cullingu, tak żeby porównanie było sensowne
  musimy je jakoś generować dynamicznie:

  Obsługujemy wiele różnego rodzaju draw-calli:
  - statyczna / dynamiczna geometria
  - z instancingiem lub bez
    indeksowanie vertexów w statycznych meshach to raczej nie problem?
	ale co ze skinned meshami ? każda instancja może też być inaczej przekształcona...
	Dodatkowo, aby wyznaczyć AABB tróəkątów i Z min/max, muszę mieć dostęp do przekształconych
	wierzchołków...
	W compute chyba ciężko będzie to zrobić lepiej niż w geometry shaderze ?
  - najgorsze, że dostępy do VBuffera mogą być dalekie od ideału. w standarodwym pipelinie mamy
    pewnie jakiś cache...
	
    Pewnie łatwiej by było jakbyśmy mieli TriPatche / meshlety; Tak czy inaczej to jest ew. na potem
    Czy meshlety działałyby też z instancjami/skinned meshami ? 

    Vertex shader przekształcał by cały meshlet? moglibyśmy też podzielić meshlet na 2 cześci:
	dane trójkątów i dane wierzchołków; jeśli robiłbym na meshletach, to 
    Czy jest sens od razu robić meshlety ?

    Czy meshlety mogą mi też pomóc z transparencją? Jeśli miałbym tam informacje o warstwach to
	mógłoby to uprościć sortowanie? Ale jak konkretnie? per pixel i tak przetwazam poszczegolne
	trojkaty? a moze po prostu przetwazalbym (i sortował) tri-patche? ok, ale co jeśli tri
	patche będą się przecinać? w takiej sytuacji lepsze byłoby sortowanie trójkątów...
	A jak już mam listę tróəkątów, to fakt, że 2 trisy są z tego samego patcha nic mi nie daje?

    Patche na pewno będą musiały być dzielone na nie-overlapujące kawałki do sortowania
  
  - Teoretycznie przekazywanie patchy aż do poziomu kafli mocno przyspieszy binowanie, ale na
	poziomie kafla może to mocno zwiększyć bandwidth? A może nie koniecznie? jeśli dałoby się
	nie ładować np. od razu całych danych wierzchołków? ale to chyba nie ma sensu?
  - Bardzo dużo zależy od tego: ile patchy średnio byśmy mieli per bin/tile/block

  - Jeśli np. w prakty tile pokrywał np. 20% lub mniej powierzchni patcha, to byłoby bardzo
	słabo...
	
  - Dodatkowy problem z tripatchami: mozna je tylko renderowac w calosci, czy moze być opcja
	renderingu zakresu tróəkątów? nie ma problemu z zakresem, będzie to zwykla maska
	trzeba bedzie troche wysilku wlozyc w przerobienie scen, tak, żeby materialy się cały czas
	poprawnie mapowaly na trojkąty
	
   - to się wydaje proste ale pewnie będzie 1-2 tyg roboty...

  Chyba lepiej najpierw zrobić prostszą metodę tak czy inaczej; CHoćby po to, żeby mozna było
  faktycznie porównac?
	
W tym problemie ważne jest chyba jak najlepsze skompresowanie danych?
  - *Problem:* to jest bardziej skomplikowane i tak naprawde nie potrzebuje tego do gry; Moze
	na początek i tak lepiej jest zrobić coś prosztszego?
	
	Ale czy da się sensownie zrobić ten renderer z normalnymi vertex & index bufferami ? tzn.
	lepiej niz geometry shader?
  - Najważniejsze: jak łączyć dane wierzchołków z trójkątami ?

  Zainstaluj Visual Studio zeby latwiej debugować ?
 
*Potencjalne rozwiązania:*
1. - TriPatche ? A co z partiklami ?
2. Jakaś detekcja warstw trójkątów ? To wszystko może być bardziej kosztowne niż zwykłe OIT...
3. Czy dałoby się szybko wykrywać nie overlapujące warstwy trójkątów dla danego rzutu ?
  dla zwykłych meshy może dałoby się coś pokombinować, ale co zrobić z partiklami ?
  albo po prostu z chmurami tróəkątów ?
  podział na warstwy po głębokości ? każdy trójkąt ma jakiś zakres głębokości (min/max po zrzutowaniu)
  można tego użyć to pokubełkowania całej geometrii;
  zostało by nam na koniec tylko sortowanie w ramach warstw.
  OK, ale warstwy mogą się overlapować; niektóre tróəkąty występowałyby w wielu warstwach ?
  jeśli warstwy byłyby w ramach binów to może dałoby się sensownie porozdzielać geometrię ?
  Ale jak dobrze wyznaczyć zakresy warstw? musi to się jakoś pokrywać z faktycznym rozkładem
  głębokości w trójkątach;
  Czy podział na warstwy zawsze jest możliwy ? Żeby było bezpiecznie, przy wybieraniu trójkątów
  muszę zawsze wybrać wszystkie które overlapują po Z; Mogą być takie sceny pewnie gdzie jest
  tylko jedna warstwa zawierająca wszystkie trójkąty
  Np. jeśli mamy na scenie duże trójkąty otaczające całą scenę, to jeden taki może 'przykleić'
  do siebie wszystkie pozostałe...

  *Może takie trójkąty wrzucajmy wiele razy z różnymi zakresami głębokości ?*
  Ale:
  - chciałbym minimalizować takie trójkąty
  - warto byłoby jakoś zwizualizować sobie przecięcia scen o głębokości
    (histogramy dla różnych binów)
  Pod problem: jak dobrze wyznaczyć zakres głębokości trójkąta przyciętego do bina?
    bin może mocno ograniczyć ten zakres...
    na Hairballu to zmniejsza ilość trójkątów o ok. 2%; Na niektórych scenach może będzie
	więcej...

  Pod problem: rozkłady trójkątów na osi Z mogą być bardzo nierównomierne... co z tym zrobić?
  Chyba muszę z grubsza posortować po głębokości w ramach bina ?
  Ale sortowanie jest kosztowne...
  Zamiast sortowania binning na 256 kubełków?
  możemy zrobić symulację ile faz byłoby potrzebne, żeby przetworzyć dany bin

  Zaczynanie renderingu z poziomu bina to często za dużo; W niektórych sytuacjach lepiej jest
  robić rendering dopiero na poziomie kafli; Można to zrobić na 2 sposoby:
  - generować listy trójkątów dla poszczególnych kafli tak samo jak dla binów i zapisywać je
    do pamięci
  - robić rendering z poziomu bina  i w pętli filtrować t©óəkąty dla kafli; Problem: zakresy
    głębokości byłyby niedostosowane do konkretnych kafli?
