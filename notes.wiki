 
 *Skupiamy się na wydajnym renderingu przezroczystości; Chcemy szybko zamknąć ten temat*
 
 czy jest sens bawic sie w vulkan teraz? docelowo i tak musoalbym to chyba zrobic, zeby
 bylo bardziej portowalne?
 - może lepiej nie, zrobmy najpierw cos dzialajacego i nie inwestujmy w to za duzo czasu!
 
*Simple 1280x1024 (full alpha)*
             normal  msaa4x  msaa16x
	 dragon:   900    1010    1100
   hairball:  5780    7380   14270
 powerplant: 13030   12540   19330
 san-miguel:  8590    9440   15790
	 sponza:  1700    1940    6390

*Stats 29.10*: total  setup  bins  tiles  raster_masks  sort_masks  final_raster
	 #boxes: 6334   25     54    136    487           1693        3513
	  bunny: 1989   48     48    96     388           487         720
 conference: 4497   94     95    251    693           1012        1788
	 dragon: 3474   309    134   217    638           737         910
	gallery: 7913   345    156   376    1326          2056        3321
   hairball: 25548  989    587   2589   11105         3834        5440
 powerplant: 31435  3873   1625  1774   10661         4854        8049
 san-miguel: 27837  2033   641   967    3821          5614        13651
  scrubPine: 2831   16     35    106    308           470         1501
	 sponza: 14820  167    167   358    1122          3221        9211
	 teapot: 2018   29     46    81     307           459         901
  white_oak: 11641  53     59    193    684           2705        7568

*Stats 02.11*: total  setup  bins  tiles  raster_masks  sort_masks  final_raster
	 #boxes: 5879   27     53    134    481           1751        3283
	  bunny: 1882   52     50    100    385           498         655
 conference: 4077   103    101   266    734           1148        1497
	 dragon: 3026   330    129   260    611           740         789
	gallery: 7564   365    152   424    1350          2127        2805
   hairball: 23023  1095   582   2423   9895          3839        4522
 powerplant: 31773  3595   1599  2390   10908         4862        6764
 san-miguel: 25494  2106   631   1289   3801          5613        11555
	 sponza: 13280  173    177   358    1101          3194        8074
	 teapot: 1857   33     46    80     302           456         815
  white_oak: 10781  56     60    186    671           2734        6923
 
*Stats 16.11*: total  setup  bins  tiles  raster_masks  final_raster
      bunny: 1975   104    48    89     1004          605
 conference: 3481   85     83    223    1697          1262
     dragon: 2858   299    128   249    1271          781
    gallery: 6494   386    147   401    2702          2708
   hairball: 39292  1023   577   2242   15445         19099
 powerplant: 32365  3800   1838  2340   11582         12317
 san-miguel: 23592  2028   627   1269   6263          13064
     sponza: 11420  164    160   330    3058          7549
     teapot: 1965   32     45    74     911           785
  white_oak: 9283   71     56    178    2252          6589
*Resolution:* (1280, 1024)

*Partial results (bins with > 1024 tris not rendered) (total time):*
    #boxes: 4559
     bunny: 1382
conference: 2512
 scrubPine: 1518
    sponza: 3802
    teapot: 1254
 white_oak: 7782

-----------------------------------------------------------------------------------------
                    === Rasteryzacja wszystkich sampli na raz ===
-----------------------------------------------------------------------------------------



* *Pomysł nr 37168* Dzielenie przecinających się masek*

- Jak to sensownie zrobić?
  - wyznaczanie wszystkich potencjalnych przecięć brute forcem jest dość szybkie (0.5ms na sponzie)

  - Jak na podstawie wykrytych przecięć wygenerować nowy zestaw masek, w których nie trzeba by już używać filtra głębokości?

  - Jeśli znalazłem przecinającą się parę, to co dalej ?
    Największy problem jejst wtedy kiedy mam grupę (>2) przecinających się warstw
	Jak porozdzielać je między wątki?
	Dzielimy zawsze wcześniejszy kolejnymi warstwami; podział na max 4 kolejne warstwy?
	W jaki sposób zapisujemy te nowe warstwy do listy ?

	Najpierw robimy sumę prefiksową dla ilości warstw a następnie wrzucamy je do SMEM?

	W tym kontekście co to jest warstwa ? Na razie robimy to dla warstw 8x8?
	Czyli 64 bity na maskę, albo 8x 6 bitów na zakresy

	Musiałbym też sortować wstępnie maski po min-Z.

	Najgorsze:
	- czy podział maski na mniejsze będzie wystarczjąco szybki, jeśli każdą maskę będę porównywał z 20-oma innymi?
	  samo policzenie jest dużo szybsze...;
	  Z drgiej strony brute force jest dosść szybki...

	OK a jak ma wyglądać samo wyliczenie przecięcia ?
	- dzielenie nie powinno być potrzebne, wystarczy dot product

	Rdir = Rbase + x * DX + y * DY
	depth = dot(normal, RDir)
	      = dot(normal, RBase) + dot(normal, DX) * X + dot(normal, DY) * y
	Czyli potrzebuję 3 liczb na każdy trójkąt: dot(normal, RDir), dot(normal, DX), dot(normal, DY)
	Mając je powinno się dać dość szybko wyznaczać przecięcie głębokości na poziomie linii

	Po wyznaczeniu przecięć dla wszystkich linii, jeśli co najmniej jedna jest przecięta,
	to robimy dwie warstwy;
	OK, ale później muszę jeszcze raz przetwarzać te dwie części niezależnie?

	Przecięcia liczymy tylko z bazową maską, później ew. rozdzielamy na mniejsze cześci ?
	To może być dość skomplikowane...

	Max 2 przecięcia na trójkąt? Niektóre (pojednycze) tókąty mogą mieć dużo więcej...
	Najgorsze w tym rozwiązaniu są właśnie edge-case-y które mogą być 100x 1000x razy wolniejsze od
	średniego przypadku; Jak sobie z nimi radzić?

	Proste przypadki obsługujemy od razu (na początek np. max 1 przecięcie) a trudne dodajemy do jakiejś listy ?

	Jak przetwarzać trudne przypadki ? Poprzez rozbijanie w odpowiedni sposób (dzielenie na w miarę równe części?)
	Możemy na razie trudne przypadki olać, zrobić tylko proste i zobaczyć ile to nas kosztuje

	Chyba dobrze by było jakoś szacować ilość przecięć głębokości i na podstawie tego przetwarzać bloki 4x4, 8x8 albo 16x16?
	Nawet jeśli to na potem.

	Kolejność zmian:
	- wyłączamy filtr głębokości: zostawiamy tylko prosty test i zaznaczamy błędne piksele
	- nie sortujemy po centroidzie ale ZMIN, wyznaczamy też ZMAX
	- wyznaczamy 3 parametry do szybkiego wyznaczania głębokości per trókąt bez dzielenia (od razu przy generacji danych trókątów)
	- wykombinować jak przechować dane warstw: Z-MIN, Z-MAX i trójkątów: parametry A, B, C do wyznaczania głębokości
	  
	- robimy proste liczenie przecięć: każdy wątek odpowiada za jeden trójkąt i testuje go z wszystkimi potencjalnymi

	A może najpierw zobaczmy jak sensownie zrobić przecięcia ?

	Jeszcze jeden problem: po pocięciu na kawałki spada koherencja cieniowania; Czy da się coś z tym zrobić?
	Czy po prostu zakładam, że takich sytuacji jest na tyle mało, że się nimi nie przejmuję?
	Na początek raczej się nie powinienem przejmować

 * *Pomysł nr 37167 (bez heterogeniczności, redukcja i cieniowanie w jednej pętli)*

 Redukcję robimy w tej samej pętli co cieniowanie, ale jest to robione na zmianę, tzn. napierw
 ładujemy ileś tam sampli a następnie je wszystkie redukujemy. Minusem jest to, że podczas
 cieniowania w rejestrach muszę trzymać filtr głębokości

 Mamy tutaj dwie opcje:
1) możemy najpierw robić pełne cieniowanie a następnie przy redukcji operować na parach
   głębokość + kolor
   + prostsze
   + nie wymaga dwóch faz redukcji
   + nie wymaga pre-computeowania wypychanych warstw
   + lepsza koherencja sampli (także pod względem danych trójkątów w SMEM)
   + można wykorzystać głębię wygenerowaną podczas cieniowania
   + można ignorować sample bez alphy

2) możemy też najpierw zrobić wstępną redukcję która będzie operowała na parach tri_id +
   głębokość (w jednej wartości 32-bit), raz na jakiś czas będzie wypychała warstwy pikseli;
   te warstwy po zapełnieniu bufora w smem cieniujemy i robimy finalną redukcję
   + wymaga mniej rejestrów na filtr głębokości
   ? łatwiej zrobić efekt mgły ?
   ? wydajniejsza pierwsza faza redukcji, ale wymaga dodatkowej fazy końcowej...

Najpierw 1). Jak ustalić porządek sampli ? Czy segmenty są tutaj potrzebne ?

Czy najpierw nie powinniśmy robić bloków 16x16 ?
A może najpierw przerobić na segmenty rzędów ?
Możemy też najpierw zrobić nowy schemat ?

Potrzebujemy tutaj też posegmentowanych rzędów sampli ?
- do redukcji musimy mieć załadowane dane segmentów (żeby było wiadomo które sample do których
  pixli przypadają)

Ale jak by wyglądała w tej sytuacji redukcja ? 8x8 i 16x16 ?
muszę też pamiętać o zachowaniu kolejności!


segmenty 16x16:
- 256 sampli, max 64 trójkąty ?
- 256 bitów na mapę bitową 

segmenty po 64 sample:
- 2 * 32-bitowa mapa bitowa z początkami rzędów (bit ustawiony tam gdzie zaczyna się kolejny rząd)
- każdy rząd ma zakodowaną pozycję w ramach bloku 16x16 (8 bitów) i sub-id trójkąta (8 bitów)
- długość rzędu można wywnioskować z mapy bitowej

Info per segment:
- id pierwszego rzędu (11 bitów)
- id pierwszego trójkąta (11 bitów)
- offset rzędu dla drugiej połowy segmentu (5 bitów)
- offset trójkąta dla drugiej połowy segmentu (5 bitów)

Info per rząd:
- pozycja (8 bitów)
- id tróəkąta (8 bitów)
- pozycje trzymamy niezależnie od idków tróəkątów? może idki lepiej jest wywnioskowywać z map
  bitowych tak jak wcześniej?
  co zajmie mniej miejsca?
  - 2/4 rzędy minimum na 32 sample, czyli co najmniej 16/32 bity na idki; przy większym
	zagęszczeniu trójkątów (dragon) mapa bitowa zajmie mniej?

Jak wygenerować info o rzędach? Max 512 * 4 / blok ?
to się zmieści, ale w smem trzymam już offsety... przenieść do rejestrów?

- przy liczeniu offsetow sampli dla trojkątów od razu zliczamy ilość rzędów i offsety rzędów?
  Problem w tym, że niektóre rzędy powinny być duplikowane...

  Co zrobić z tą duplikacją?
  - mając offset i ilość fragmentów na tróəkąt możemy stwierdzić ile fragmentów wypadnie na
	który segment (może być więcej niż 2)
  - dla każdego segmentu od razu dać dodatkowy rząd (początkowy), ale jak dobrze wyznaczyć
	offsety?
	- tróəkąty rozpoczynjące się wewn. segmentu

  - docelowy offset rzędu to prefix suma licznika rzędów po trójkątach + nr segmentu;
    jeśli rząd zaczyna się od początku segmentu to offset -= 1

  Problem: wymaga dodatkowego przebiegu po zakresach sampli tróəkątów;

  żeby poumieszczać rzędy na odpowiednich pozycjach muszę mieć offsety?
  dopiero po posortowaniu można określić jakie rzędy znajdują się w jakich segmentach
- nie przechowam danych o zakresach tróəkątów w SMEM bo nie ma na nie miejsca...

  chyba, że przechowam w rejestrach? 16 rejestrów potrzebne... czy to dużo? powinno być ok
- problem: tak naprawdę używana jest do tego cache-owana pamięć globalna; hgw czy da się to
  sensownie zunrollować

  teraz na tróəkąt/block zapisuję do pamięci 4x 32 bity (to wszystko na 64 sample)
  na rzędy potrzeba max 2x 32 bity dodatkowo na sample: 3x 32 bity; Czyli w przypadku pełnych
  trójkątów będzie więcej danych
  
  W przypadku małych tróəkątów: 8 bitów na rząd, 8-16 bitów na bitmapy ?
  Czy da się jakoś zmniejszyć dane na bitmapy ?



 * *Pomysł nr 37166 (najpierw redukcja do listy małych sampli)*

Jeśli miałbym ilości per pixel + offsety to mógłbym generować listy sampli tylko za pomocą
idków tróəkątów (8-9 bitów na trójkąt). Ale jak to później wydajnie pocieniować?

Zapisywanie kontekstu początkowej redukcji? 32-bity na próbkę, po wygenerowaniu odpowiedniej
liczby sampli (np. 512/1024)

Generowanie mini-sampli pogrupowanych po warstwach?

Co robię z mini-samplami ? Cięzko je teraz pogrupować po tróəkątach... 
najpierw paprallel prefix sum dla wyliczenia ilości
potem offsety i na końcu indeksy...
wydaje się dość kosztowne...

Z drugiej strony, czy nie mogę wygenerować warstw wcześniej ? może drobne zamiany kolejności
nie wpłwają na same warstwy?

Jak te warstwy będą wytwarzane ?
- w wyniku przepychania sampli przez filtr głębokości, w niektórych pikselach będą generowane
  sample. Warstwy tworzymy ballotem. Zapisujemy mapę bitową zamiast indeksów sampli; Czy to
  zależy tylko od ilości sampli per pixel, czy od wartości sampli ?
  
  Jest to niezależne od wartości, więc generalnie warstwy można wygenerować przed samą
  redukcją. Ale raczej nie pomoże i to w grupowaniu sampli per-tri po redukcji...

  A może olać porządkowanie i po prostu założyć, że porządek będzie jako taki ? jeśli bym
  przetwarzał bloki 16x16, to może byłoby to wystarczające ? Tylko przy przecięciach byłyby
  problemy z koherencją ?

  Chyba najlepiej je teraz olać...
  
  Ale w takim razie czy nie lepiej po prostu od razu cieniować przy redukcji ? Jedynym minusem
  jest obciążenie rejestrów. Ale może to się opłaca ?

  minusem jest to, że trzeba będzie encodować/dekodować wartości kolorów


 * *Pomysł nr 37165 (cuda)*

Czy chcę to zrobić na CUDZie czy nie ?
Albo CUDA albo Vulkan...
- Vulkan daje przenośne operacje na subgrupach i większą kontrolę nad GPU ale nie daje lepszych
  narzędzi do heterogenicznych obliczeń
- CUDA ma chyba wszystko czego potrzebujemy

Mogę też spróbować zrobić heterogiczne obliczenia w opengl, ale może to być wolniejsze niż bez
tego... więc czy to ma wogóle sens ?

Robiąc na cudę mógłbym użyć whippletree, ala najpierw musiałbym to naprawić...

heterogeniczność jest potrzebna zeby zmiescic w SMEM adane trisow
Problem: jeśli kolejki będą wolne to heterogeniczność nic nie da...

 * *Pomysł nr 37164 (zapisywanie rzędów oddzielnie)*

- Dla każdego segmentu mamy mapę bitową (32 bity). Bit jest ustawiony jeśli w danym pikselu
  zaczyna się następny rząd
  Dodatkowo mamy id-k pierwszego trójkąta i pierwszego rzędu
- Każdy rząd wymaga: 6/8 bitów na pozycję (zależnie od wielkości bloku) i 5-8 bitów na sub-id
  trójkąta; Zaokrąglamy do 16 bitów
- Oprócz tego potrzebujemy jeszcze listy idków tróəkątów (idki w ramach całego bina)


Jak wykorzystać informacje o rzędach do szybkiej redukcji?
- wszystkie piksele po prostu przelatują po wszystkich rzędach, szybko filtrując te rzędy które
  faktycznie się pokrywają z danym pikselem
- rzędy mogą być załadowane razem z danymi tróəkątów ? czy będziemy mieć na nie miejsce ?
  moglibyśmy przesyłać razem z samplami oprócz pozycji pixela odległość do końca danego rzędu,
  to umożliwiłoby w miarę szybkie przeskakiwanie po samplach?
  
- W takiej sytuacji nie musimy wymyślać struktury danych która się nadaje też do redukcji,
  wystarczy że umożliwi szybką generację.
  
  To możemy zrobić teraz, ale pomysł z redukcją używającą pozycji sampli bezpośrednio
  zakodowanych będzie wymagał rozdzielenia redukcji od cieniowania.
  
  Czy da się zrobić sensownie połączone ładowanie danych tróəkątów + segmentów na zmianę z
  cieniowaniem ?
  - nie mogę używac barier...
  czy wogole da się sensownie ładować dane t©óəkątów bez barier ? chyba bez dużych overlapów
  nie...
  chyba że warpy niezalenie by operowały na segmentach?

 * *Pomysł nr 37163*

TODO: nowy pomysł na loadSamples:
nie robimy wogóle loadSamples, zamiast tego na koniec generateBlocks generujemy
segmenty i używamy ich przy cieniowaniu do wykminienia jaki tróəkąt i jaki pixel cieniujemy

Trik na zakodowanie mapowania max 32 tróəkątów w ramach 32 pikseli:
wystarczą do tego 32 bity:
bit jest ustawiony na 1 jeśli w danym pikselu mamy nowy tróəkąt

cur_pixel_mask = uint((1 << (pixel_id + 1)) - 1
- wyznaczenie który tróəkąt teraz cieniujemy: bitCount(segment_mask & cur_pixels_mask) - 1
- wyznaczenie offsetu w ramach danego tróəkąta: findMSB(segment_mask & cur_pixels_mask) - pixel_id

Oprócz tego dla każdego segmentu musimy też wyznaczyć id pierwszego trójkąta i jego początkowy offset

Dla każdego bloku mamy listę max 512 tróəkątów. Bitmaski dla tróəkątów cały czas będą potrzebne
Oprócz tego trzymamy też max 256/512 64-bitowych segmentów ?
Każdy segment to 64-bity + id trójkąta (11 bitów) i offset (6 bitów)

Jak te segmenty najszybciej wygenerować?

Czy mogę jakoś użyć tej informacji / sposobu do tego, żeby przyspieszyć redukcję ?
- wygenerowanie list per-pixel ? Ale jak wyznaczyć poprzedni pixel ?

  __match_sync byłoby przydatne do wyznaczenia sampli o tych samych koordynatach...
  łatwo przeskoczyć sample z tego samego trójkąta, ale w przypadku dragona brute force może być wolny...
  zakodowanie offsetów dla rzędów pixeli?

segmenty są 32-bitowe ? raczej tak będą się lepiej mapowały na warpy?
ale za to będą więcej zajmować ?

potrzebujemy:
- id trójkąta (w ramach bloku? tak: 9 bitów)
- offset tróəkąta (6 bitów)
- bitmapę (32 bity)

zapisujemy po prostu 2x 32 bity; bitmapy zapisujemy w SMEM? a gdzie id-ki ? na razie max 128? i tyle


Co zrobić, żebyśmy nie musieli zapisywać offsetów trójkątów do redukcji?
- zwięźle raczej nie zakoduję informacji o tym jakie sample należą do jakich pikseli
- ale może nie muszę? może dałoby się to szybko wyznaczyć? np. za pomocą sync_match ?
  czy jest jakaś alternatywa?

  po bitach? jak znależć wszystkie wątki które mają ten sam bit ustawiony w ten sam sposób?
  ballotem tego nie zrobię...

Jaka jest ogólna struktura danych tego co przetwarzam ?

- każdy trójkąt ma maski pikseli które pokrywa w danym bloku; w każdym rzędzie jest to nie
  przerwany ciąg sampli
- sample trójkątów są ułożone jeden za drugim


Musimy być w stanie szybko:
- dla danego sampla K z segmentu N: do jakiego trójkąta należy i który pixel jest cieniowany
  - dla danego piksela wyznaczyć wszystkie sample w jakimś zakresie (segment albo grupa
	segmentów)
  - albo: dla danego sampla wyznaczyć następny sampel w danym pikselu
  - przelicza


Odpalenie redukcji na równoległych wątkach na pewno też coś będzie kosztowało a w niektórych
sytuacjach nie da zysku (nie licząc z zysku na załadowaniu danych tróəkątów do SMEM) bo ilość
sampli nie jest na tyle duża, żeby się nie mieściły...


* *Luźne myśli*

Skompilkowane rozwiązania też kosztują, na Sponzie np. często mamy bardzo proste sytuacje które
wogóle nie wymagają zaawansowanych algorytmów do obsłużenia.

Ale kilka różnych strategii raczej nie wchodzi w grę, bo muszę też brać pod uwagę wielkość
shadera.

Proste rozwiązanie źle sobie radzi w sytuacjach w których są duże różnice w samplach między
pikselami. Mogę zminimalizować ten efekt jeśli dobrze pogrupuję piksele.

Bardziej skomplikowane rozwiązania minimalizują ten efekt przez wydzielenie samplowania, także
problem różnych ilości sampli/pixel dotyczy już tylko ładowania i redukcji. Ale te dodatkowe
skompilkowanie dodaje też stały koszt... (generowanie/zapisywanie i odczytywanie sampli do/z
SMEM).

Może jeśli sąsiednie piksele są blisko siebie to koszt różnic w ilościach sampli nie jest tak
duży? Na whiteoak same samplowanie to ok. 1/6 całego czasu rasteryzacji...

Cały warp po skończeniu pracy mógłby się przełączać na kolejny kawałek?

Prosta wersja jest wolniejsza od skomplikowanej nawet na sponzie (czemu?).


* *Nowy pomysł (Producer + Consumer):*

Wersja 1:
- ładowanie trójkątów i generacja sampli
- cieniowanie sampli
- redukcja sampli

Wersja 2:
- ładowanie danych tróəkątów
- wstępna redukcja sampli
- cieniowanie sampli
- ostateczna redukcja sampli

* *UWAGA:* filtr głębokości raczej musi być wykonywany w ostatecznej fazie redukcji; inaczej w
  niektórych sytuacjach na zbyt długo mógłby zablokować załodowany trójkąt (mógłby pewnie
  doprowadzić do deadlocka).

Wszystkie taski działają na małych buforach (np. max 128 trójkątów, max 512 sampli), warpy
co jakiś czas znajdują sobie jakiś task do zrobienia i je wykonują. Wykonanie taska zwalnia
miejsce w buforze i umożliwia wykonywanie kolejnych tasków z poprzednich faz.

Task redukcji jest wyjątkowy, bo raz zassignowany do warpa kończy się dopiero jak wszystkie
sample z danego bloku zostaną przetworzone.

Problemy:
* *jak zachować kolejność sampli w takim przetwarzaniu?*
  - task cieniowania ma 32 sample z jakiegoś tam bloku i z jakimśtam offsetem
  - reduktor nie może redukować tych sampli na chama, musi przetwarzać w odpowiedniej
	kolejności
  - sample z różnych bloków są całkowicie niezależne, ale sample z jednego bloku już nie...
  
  - musiałbym ustawić takie limity na taski ładowania sampli, żeby nie generować tego za dużo?
  - ładowarka sampli też chyba najlepiej, żeby generowała sample od początku do końca?
    z drugiej strony, co jeśli nie będzie miejsca w buforze?

* *jak zapewnić, że wszystkie warpy przez większośc czasu mają coś do robienia?*
   


* *jak zrobić wydajne przełączanie się miedzy taskami ?*
  Taski to po prostu K-bitowe liczniki trzymane w jednej wartości ?
  
  mamy liczniki tasków do zrobienia i dodatkowo miejsca na dane tasków. Jednostką są np.
  32 trójkąty albo 32 sample

  * *TODO: poszukać producer/consumer on a GPU* | ordered atomics GPU


- jak przetwarzać wiele bloków na raz i nie zagłodzić niektórych tasków ?
- jak wydajnie zrobić wstępną redukcję sampli ?

* *Późna redukcja wybranych sampli:*
  przy ładowaniu sampli, sample są w kolejności po trójkątach, jak redukcja mogłaby
  zgarnąć te dane wydajnie ?
  
* *Jak zrobić finalną redukcję z wersji #2?*
  musiałbym mieć miejsce w SMEM na docelowy kolor
  chyba, że miałbym jeden (zpinowany) task który działa dla danego bloku od początku do końca?
  jeden wątek mógłby obsługiwać np. 2/4 piksele?

* *Jak zrobić cieniowanie w wersji #2?*
  - muszę mieć sample w kolejności tróəkątów i wygenerować je w kolejności pikseli

* *Podstawowy problem:* jak w trakcie generowania sampli w kolejności po tróəkątach od razu
  wygenerować informacje o kolejności do pikseli, które można by użyć przy redukcji?

  Opcje:
  - generacja kolejności przy generowaniu sampli i zapisanie w oddzielnej tablicy albo w
	sample id-kach
	
  - szybkie znajdowanie sampli dla odopwiednich pikseli w czasie redukcji?
    powiedzmy, że mamy 512 sampli, w każdym informacja o tym który to piksel (jeden z 64)
	dodatkowo mamy 64 wątki, każdy odpowiada za któryś piksel
	
	każdy wątek bierze 1 sampel i za pomocą atomiców 

* *Nowy schemat*

1) generujemy bloki: mamy ustalone bx_step: 1, 2, 4 albo 8
   możemy processować bx_step bloków na raz
  
2) mergujemy id-ki trójkątów z wybranych bloków:
   512 bajtów danych; potrzebne do generowania sampli

3) generujemy sample w kolejności po trójkątach:
   potrzebujemy zmergowanych id-ków
   4 bajty na próbkę: 8KB danych; 8 bitów na id trójkąta, 9 bitów na pozycję piksela

4) ładujemy idki sampli do rejestrów

5) ładujemy dane trójkątów do SMEM

6) cieniujemy sample, wyniki zapisujemy w rejestrach (16 bitów na kolor: 7 rejestrów)

7) generujemy sample w kolejności po pikselach; od razu ustalamy docelową kolejność, do tego
   potrzebujemy już załadowanych bazowych danych trójkąta (równanie płaszczyzny) i
   zmergowanych idków
   16-bitów na próbkę: 4KB danych

8) wrzucamy ocieniowane sample do SMEM pod pozycje pikseli

9) Prosta redukcja, powinno się dać zrobić szybko niezależnie od bx_stepa

Musimy być w stanie przechować w tym samym momencie w SMEM:
- 4KB (idki sampli w kolejności po pikselach); 18 KB danych trójkątów; 512 bajtów na zmergowane idki

Zadania 8 i 9 możemy wykonywać w tym samym czasie;
Jak dobrze rozłożyć pracę? Jeśli generowanie sampli skończy się przed cieniowaniem to co wtedy?
Musiałbym zrobić jakiś prosty alokator sampli? Mamy ileś tam warpów do pocieniowania i pierwszy
wątek w każdym warpie alokuje 32 sample dla każdego warpa i tak w pętli aż się skończą sample
Powinno być proste?

* *Inne podejście: generujemy nie-precinające się warstwy sampli*


  - po posortowaniu trójkątów porównujemy t©óəkąty które pokrywają się ze sobą wartościami
	głębi
  - dla każdej takiej pary próbujemy znaleźć przecięcie: sprawdzamy które sample z trójkąta A
	są pod a które nad trójkątem B. Sample rozrzucamy do dwóch nowych kawałków

  Problem: przecięć może być dużo; Jak zrobić, żeby nie wymagało to więcej pracy niż zwykłe
  porównywanie sampli ?

* *Co dalej?*

Jaka strategia byłaby najlepsza ?

Raczej na pewno chcemy oddzielić redukcję od cieniowania ?
- kolejność sampli po trójkątach robi dużo jeśli mamy oteksturowane trójkąty
- możemy zrobić dużo lepszy load balancing niż w final_raster (odpalamy dokładnie tyle wywołań
  ile jest sampli)

Może dałoby się wygenerować małą ilość sampli (a nie zawalać cały SMEM) i od razu je zredukować?

Z drugiej strony jeśli ilość sampli per piksel jest podobna i nie używamy tekstur (Dragon) to
strategia taka jak w final_raster może być lepsza, bo nie przekazujemy sampli przez SMEM ale od
razu redukujemy.

Ale wciąż jest zbyt wolne:
- ładowanie atrybutów
- redukcja (szczególnie jeśli mamy mniej pikseli niż wątków)

Problem:
- 64x8 = 512
- filtr głębokości wielkości 8: 4 x 32 bit na kolor + 4 x 32 bit na głębię + kolor docelowy ?


To może tak:
- dużo mniej sampli na wątek (np. max 2)
- efektywna redukcja (ale jak) ? jeśli miałbym sample ułożone po pikselach, to wtedy by się
  dało zrobić redukcję efektywniej. dodatkowym problemem jest to, że połączenie sampli nie jest
  oczywiste, bo ja ich nie sklejam, ale tak naprawdę sortuję...

Fakt jest taki, że jeśli chciałbym całościowo wykonać redukcję niezależnie na rejestrach, to
musiałbym mieć wygenerowane wszystkie sample dla danych pikseli.
To też oznacza, że to się będzie słabo skalowało na bardziej głębokie piksele.


CHyba, że da się przyspieszyć redukcję, żeby działała szybko niezaleznie od ilości pikseli...
ALE JAK?!?


Wykonywanie redukcji na zmianę z cieniowaniem ?
- kolor docelowy + stos głębi trzymany w rejestrach (każdy wątek odpowiada za inny piksel)
- muszę być w stanie szybko identyfikować sample dla danego piksela

  - indeks pierwszego sampla dla danego piksela
  - indeks ostatniego sampla dla danego piksela
  - indeks kolejnego sampla dla danego sampla

 
 
 Ile trójkątów mogę załadować ?
 8 na 32 wątki ?
 Jeśli będę miał < 4 sample na trójkąt to będzie słabo!


 Jeden trójkąt: 28 * 32 bit / 4 = 7 * 32 bit
 Za dużo... max 1 tróəkąt na 8 wątków
- to oznacza, że jeśli mam średnio mniej niż 8 sampli na tróəkąt, to jest problem
  chyba, że w tej sytuacji ładujemy z GMEM ? to chyba lepsze niż słaby load balancing ?

Jeśli się zmieścimy w 16KB, to można by zmieścić 3 bloki? chyba nie: używamy za dużo rejestrów...


Jak zrobić dla każdego piksela listę sampli ?

loadSamples nie będzie w stanie tego zrobić bez sychronizacji ? Chyba, że bym odpowiednio
podzielił przetwarzane trójkąty ?
Mógłbym w loadSamples przetwarzać każdy rząd innym wątkiem:
- 8 wątków na trójkąt 
wtedy sync nie jest potrzebny


 Chyba, że bym trzymał quady, ale wcale nie jest pewne, że będę trafiał!



* *Nowy algorytm:*
  - ogólny pomysł: generujemy małe ilości sampli i od razu je redukujemy
  - podczas ładowania sampli generujemy od razu listy sampli per piksel
  - dla załadowanych sampli ładujemy też dane trójkątów do SMEM (max 8)
  - każdy wątek cieniuje jedną próbkę, zapisuje ją w rejestrze (głębia + kolor)
  - następnie każdy wątek redukuje sample z listy; indeks bierze z SMEM a wartość głębi koloru
	za pomocą shuffli


* *Problem:* jeśli będę generować sample w ramach bloków 8x4 (32) to w sytuacjach gdy różne
  warstwy są z różnych materiałów to będę miał bardzo słabą koherencję. Najlepiej by było
  generować sample pogrupowane po materiałach. Ale czy da się tak sensownie zrobić?

* *Problem 2:* nie mogę zapominać, że muszę też obsłużyć piksele z błędną kolejnością

  Czy da się generować sample koherentnie z różnych bloków 8x8? Chciałbym je generować w
  kolejności materiałów a następnie redukować w kolejności docelowej
  A może po prostu ograniczyć się do bloku 8x8 ? nie ma opcji, żeby trzymać w jednym wątku
  filtr dla dwóch pikseli

  możemy na razie olać problem wielu materiałów...

  32 sample (z połówki bloku 8x8) wymagają:
  - indeksy headów dla pikseli (8 bitów na indeks = 8 * 32 bit)
  - indeksy sampli (pixel_id : 9 bitów, triangle_id: 11 bitów,
  -                 indeks następnego sampla w danym pikselu: 8 bitów) = 32 * 32 bit

  max 32 pikseli, max 32 tróəkąty, max 32 sample na segment
  indeksy sampli: pixel_id: 5 bitów, tri_id: 5 bitów, pixel_tri_id: 5 bitów
  32 sample = 16 * 32 bit
  
  - indeksy headów: 5 bitów na indeks = 6 * 32 bit
 
  22 * 32 bit na segment = 1408 bajtów na 512 wątków, 1 segment / warp = 5.5KB na 4 segmenty / warp
  11kb na 8 segmentów
  
  Czy jest sens na siłę wciskać te obliczenia do jednego warpa?
  Chyba warto uniknąć barier, żeby warpy mogły faktycznie niezależnie pracować
  Może nawet mógłbym warpa który skończył pracę oddelegować ko kolejnych bloków ?
  z barierami byłoby pod tym względem ciężej

  Problem kiedy mielibyśmy mało trójkątów
  
  *Generowanie indeksów sampli:*
  - Musimy to generować w paczkach po 32 sample
  - za każdym razem zaczynamy z jakiegoś offseta (zawsze jest podzielny przez 32); problemem
	jest zamiana offseta na parę (id tróəkąta, offset w ramach trójkąta)

  - jak to zrobić wydajnie ?

  - kilka opcji: jeden trójkąt obsługiwany przez 4 (8x pix), 8 (4x pix) wątków na raz
    różne grupy wątków generują sample z różnych segmentów;
	mogą więc operować na tych samych tróəkątach ?
	
	każdy wątek leci po jednym trójkącie na raz
    najpierw musielibyśmy wyznaczyć offsety na początki każdego segmentu:
	- 11 bitów na id trójkąta, 5 bitów na id sampla
	- możemy użyć do tego offsetów trójkątów; nie muszą być sumowane między blokami

  Schemat działania:
  - generowanie offsetów segmentów: dla każdego segmentu para: id pierwszego tróəkąta i offset
	w ramach tróəkąta
  - generowanie  sampli z użyciem offsetów (raczej 8 wątków na trójkąt)

* *TODO: jeszcze lepsza kolejność sampli?*
  Na przemian pary sampli z dwóch rzędów ?

* *TODO: raster quadów 2x2*

	*Problem:* wyliczanie pochodnych za pomocą shuffli, prawie nic nie przyspiesza:
             Na WhiteOak 12.80 -> 12.76 ...
	// TODO: use dfdx/dfdy
	vec2 bary_dx, bary_dy;
	{
		vec2 bary_nx = shuffleXorNV(bary, 1, 32);
		vec2 bary_ny = shuffleXorNV(bary, 2, 32);
		bary_dx = (bary_nx - bary) * ((LIX & 1) == 0? 1 : -1);
		bary_dy = (bary_ny - bary) * ((LIX & 2) == 0? 1 : -1);
	}
    W takim razie problem jest gdzieś indziej...

* *Problem: cały czas wolne samplowanie...*
  WhiteOak: 20ms vs 2.4ms ...
  
  Opcje:
  - Cieniowanie 2x2, 4x4, 8x8 ? 
  - Używanie SMEM do trzymania danych trójkąta ?
  - Jeszcze więcej wątków ?

* *Problem: będą też sytuacje gdzie sample nie będą poprawnie posortowane po zastosowaniu filtra*
  W takiej sytuacji będziemy musieli robić pełny sort? Będziemy musieli go w każdym razie
  lepiej zoptymalizować, żeby nie wykonywać aż tyle kroków; na pewno się da, tylko wymaga
  wysiłku
  Dodatkowo trzeba będzie generować głębokości;
  Problem: jeśli w s_bufferze będziemy mieli po 8 sampli na piksel, to nie zmieszczą się tam
  dane głębi...

  W takiej sytuacji generujemy sample od nowa?

* *Nie encoduj wielkości ekranu w shaderach: recompute przy resize*

* Trzymanie danych cieniowania dla każdego tróəkąta oddzielnie (i przeliczenie tego w setupie)
  trochę przyspiesza rasteryzację, ale nie dużo: 7.2 -> 6.54...
  A było to dla wszystkich trójkątów i nie licząc czasu na ich precompute-owanie...

* Iterowanie po tile-ach a nie po binach w raster_tile dla całej grupy tez nie pomaga (choć
  teoretycznie jest bardziej cache friendly...)

Inny pomysł:
-trzymanie razem danych wierzchołków w różnych buforach:
  uv+color+normal

Sceny:        frag/4x4    tris/4x4
Hairball:      1500        1000
Powerplant:     700         300
Sponza:         150         30
Dragon:          50         20

W przypadku hairballa możemy co najwyżej rasteryzować do 8x8 (i tak nie zawsze i przy 1024
wątkach), większe będą miały za dużo fragmentów.

Co możemy zrobić z dużymi ilościami trójkątów? Jeśli liczba fragmentów się zmieści, to nie
powinno być problemu? Po prostu nie wszystkie tróəkąty będą pre-computeowane?

* *Problem: jak mamy dużo tróəkątów na kafel to jest wolno*
  - w przypadku sponzy ta nowa strategia działa całkiem dobrze...

* *Problem: wolne cieniowanie*
  Jak to przyspieszyć? wiele pikseli z jednego trójkąta w ramach jednego wątku?
  - duże sample (4x) i małe sample?
  - co jeszcze możemy zrobić?
  - dla wybranych dużych tróəkątów ładujemy też parametry wierzchołków do SMEM?
    czy problem jest z ładowaniem czy obliczeniami?

  Dwu fazowy raster (najpierw generujemy głębokości + id trójkątów), sortujemy
  problem: jeśli będziemy rasteryzować posortowane sample, to stracimy na koherencji
  przy samplowaniu...

* Spawnujemy tyle wątków, żeby dało się zrenderować wszystkie sample do SMEM. Jeśli sampli
  jest za dużo na dany kafel, to zawężamy zakres pikseli (16x16, 8x8, 4x4).
  Np. 1024 wątki powinny pozwolić spokojnie na 2048 sampli.

* Najpierw musimy oszacować ile fragmentów mamy w każdym pikselu. Wyznaczamy też offsety
  dla każdego piksela.

* Teraz musimy równomiernie rozłożyć pracę cieniowania pomiędzy wątki. Jest kilka podejść:
  - Zaraz po wygenerowaniu masek dla trójkątów, bucketujemy maski wg. ilości fragmentów.
	Następnie każdy tróəkąt przydzielamy dla innego wątku. Taka metoda może dobrze działać jak
	mamy dużo tróəkątów i mało sampli na trójkąt.
	
  - Bardziej zbalansowana metoda: równomiernie rozdzielamy sample z trójkątów między wątki
	(sąsiednie wątki mogą pracować na tym samym trójkącie).
    - Prefix Sum po ilości sampli w trójkątach. A następnie każdy wątek znajduje swoje sample binarnie?
	  da się lepiej?
	  troszkę hierarchicznie: znajdujemy min/max indeks najpierw dla każdego warpa a następnie
	  w ramach warpów.
	  
	  Uwaga: jeśli mamy więcej niż dwa sample na wątek, to może się zdarzyć, że jeden wątek
	  obsługuje dwa trójkąty? TODO
      
	  Dla każdego wątka będziemy mieli przydział (id_trójkąta, id_sampla_w_trójkącie)
	  Jak wyznaczyć pozycję piksela ?

      Chyba, że najpierw bym wygenerował pozycje sampli w SMEM a następnie je po prostu
	  zgarniał?
	  
	  Generowanie pozycji:
	  - trójkąty są posortowane wg. ilości sampli (bucket sort); każdy wątek dostaje jeden
	    tróəkąt i iteruje po samplach...
		To jest słabe... czy da się lepiej?
	  - zależy od tego jaką mam reprezentację...
	  - TODO: do rozwiązania!
	  
* Następnie robimy cieniowanie. Każdy wątek teraz wie jaki cieniuje tróəkąt i w jakiej pozycji.
  Ale nie ma jeszcze danych trójkąta! Więc zanim zajmiemy się cieniowaniem, najpierw robimy triangle
  setup. Używamy do tego tego samego miejsca którego docelowo użyjemy do sampli. Zakładamy
  tutaj, że całe dane trójkątów się zmieszczą w SMEM. jeśli nie, to zawężamy...
  
  Na każdy trójkąt używamy jednego wątka: wyliczamy wszystko potrzebne do wyznaczania
  głębokości oraz współrzędnych barycentrycznych.
  
  Jeśli mielibyśmy też więcej miejsca (np. ilość trójkątów 2* mniejsza niż ilość miejsca)
  to robimy special case gdzie ładujemy też np. koordynaty UV, etc.
  
  Po załadowaniu tróəkątów do SMEM wszystkie wątki ładują odpowiadające im dane trójkąta do
  rejestrów. TODO: Zakładamy, że każdy wątek może obsługiwać max 1 trójkąt.
  Robimy synchronizację i w tym momencie dane trójkątów w SMEM nie są już potrzebne.

  Cieniujemy wszystkie sample i wrzucamy je do SMEM używając atomowych liczników per pixel
  (mogą być 16-bitowe).
  
* Mamy wygenerowane sample w SMEM, teraz musimy te sample w ramach każdego piksela.
  Dostępne opcje:
  - jakiś segmented sort (TODO: czy bitonic sort da się przerobić na taki?)
    bitonic sort musiałby działać tak, że w każdym wątku musimy wiedzieć, do jakiego segmentu
	należy aktualna i porównywana próbka. jeśli są różne to nic nie robimy?
    zrobienie tego na shuffle-ach może być problematyczne...
	na początek możemy zrobić bez shuffle-i
	
* Po posortowaniu musimy zmergować wszystkie sample w ramach każdego z pikseli. Robimy coś w
  rodzaju segmented reduce.
  
  Np. mamy sample S0, S1, S2, S3, ..., SN
  Chcemy wyliczyć:
  ( ... (Back.col * (1 - S0.a) + S0.col * S0.a) * (1 - S1.a) + S1.col * S1.a ...) * (1 - SN.a) + SN.col * SN.a

  Łączymy sample hierarchicznie, przy czym zamiast trzymać (Color, Alpha) lepiej trzymać:
   (Color * Alpha, 1 - Alpha), takie sample łatwiej się merguje:
   
   Merge(S0, S1) = (S0.premul_color * S1.neg_alpha + S1.premul_color, S0.neg_alpha * S1.neg_alpha)

   Robimy segmentowaną redukcję używając tej funkcji Merge. Tak samo jak z sortowaniem:
   mergujemy tylko jeśli sample należą do tego samego piksela.
   
   W samplach encodujemy pozycję piksela, czy każdy wątek z innego źródła wie który to piksel?
   - jak z innego źródła ? Z offsetów sampli per pixel ?
     Vectorized search od nvidii (pdf na lapku), ale na razie chyba po prostu każda próbka zajmie 40 bitów?

   - 24 bity na głębokość
   - 8 bitów na alphę
   - 11 + 11 + 10 bitów na RGB ? wystarczy? jeśli nie to możemy jeszcze z 8 bitów przeznaczyć? 13 + 14 + 13
   - 8 bitów na pozycję piksela
    Np. 2048 sampli: 8KB głębia + alpha, 8KB kolory, 2KB na pozycje piksela
  
  Po redukcji (bedzie tu pewnie trochę zabawy z wydajnymi dostępami do SMEM) zapisujemy
  wartości pikseli do Framebuffera i voila!
  
  Problem: MSAA! jak rozdzielić funkcję widoczności od cieniowania?

=== Pierwsza implementacja ===

- przerabiamy mask_raster:
  - wywalamy sort
  - generujemy maski (16x16) do scratcha, bez wyliczania głębokości!
    - na razie poo prostu generujmy 4 uinty i tyle!

  - jak szybko zliczyć sample w pikselach?
    - tablica +1 / -1
	- na końcu prefix sum? 2 rzędy liczymy równocześnie (16-bitów)

  - na początek tylko wyświetlanie ilości pikseli, nic więcej



-----------------------------------------------------------------------------------------
                                      === Różne ===
-----------------------------------------------------------------------------------------

*Nowy pomysł !!!*
- rendering wszystkich sampli na raz
  (możemy renderować cały tile jeśli się zmieszczą, jeśli nie to bloki 8x8 albo 4x4).
- wrzucamy wszystkie sample do SMEM
- sortujemy i robimy redukcję po pikselach (segmentowana?)
  Problem: nawet jeśli sample się zmieszczą w SMEM to tróəkąty już nie muszą.
  nie mogę też zająć całego miejsca w SMEM samplami pewnie

  Jeśli trójkąty byłyby posortowane wg. ilości sampli (można by je pobinować)
  to generacja mogłaby być całkiem szybka?



  Problem by był tylko jeśli mielibyśmy np. bardzo mało tróəkątów per bin, ale taką sytuację
  BARDZO ŁATWO można obsłużyć prostszym algorytmem!


*Sortowanie niektórych trójkątów per tile a niektórych per blok; a potem mergowanie ich?*

* Po fazie binowania może lepiej by było nie generować wszystkich danych, ale używać scratcha,
  od generacji indeksów trójkątów per tile aż do finalnej rasteryzacji. Tym sposobem można by
  mocno ograniczyć zużycie pamięci a może też ilość operacji na pamięci (ale raczej tylko w
  przypadku małych binów).


*Binowanie tróəkątów w tile-ach po ilości linii a następnie generowanie linii dla całego tile-a od razu*
- tam gdzie wiemy że będzie <= 4, 8, 12 linii możemy użyć mniej uintów do zapisania masek

*Potrzebujemy różnych strategii na różne sytuacje!*

warstwy są na zmianę? w aktualnym algo to nie jest proste: iteruję po maskach i testuję bity...
iteracja po co drugiej warstwie?

Co mi to da oprócz dodatkowego skomplikowania? Będzie trzeba załadowac 2x tyle tróəkątów i
tak...

-----------------------------------------------------------------------------------------
                             === Nowa finalna rasteryzacja ===
-----------------------------------------------------------------------------------------

- Odpinamy wątki od pixeli
- framebuffer trzymamy w SMEM (może być w częściach)

Problem: jak wątki zapisują sample do framebuffera w SMEM, to co robić z kolizjami?
  atomowo tej operacji nie zrobię, bo jest skomplikowana...
  DUPA!!!
  
  W jakiś sposób pakować więcej wątków per pixel i później serializować wyniki?
  Dzięki temu będzie można lepiej współdzielić dane tróəkątów, a sam commit do framebuffera
  powinien być szybki?
  
  
  Jak zrobić szybki commit z dużej liczby wątków do wspólnego Framebuffera?
  A może z większą liczbą wątków mógłbym łatwiej trzymać wszystkie trójkąty w SMEM?
  Np. 512 trójkątów od razu? Bloki z małą liczbą tróəkątów bym załatwiał małymi kernelami?

  Musiałbym tylko zapewnić poprawną kolejność! Ale jak to wymusić na tak dużej liczbie wątków?
  
  Najpierw wszystkie wątki rasteryzują 4 piksele powiedzmy a potem jest commit po wszystkich w
  odpowiedniej kolejności.
  
  Problem: jeśli są duże różnice w ilości pikseli per trójkąt, to wątków musi być co najmniej
  kilka razy mniej niż tróəkątów, inaczej niektóre skończą wcześniej i będą czekać.
  
  To oznacza, że muszę być w stanie dzielić pojedyncze trójkąty między wątki...
  
  W takim razie może trzymajmy trójkąty w SMEM? Jeśli możemy zaalokować więcej wątków, to mamy
  też więcej miejsca na trójkąty?
  
  Ale musielibyśmy być w stanie załadować wszystkie tróəkąty? 512 wątków 384 tróəkąty?
  Początkowo 256 wątków na blok? 
  
  
  OK ale muszę wykminić jak zrobić commitowanie...
  
  Wątek który ma próbkę do zacommitowania musiałby czekać aż wszystkie próbki przed nim w danym
  pikselu zostały zacommitowane.
  
  
  
Alternatywny pomysł: mergowanie masek. Do tego jest potrzebne jedynie wyliczenie głębokości.
- nie potrzebowalibyśmy filtra głębokości na koniec, musielibyśmy tylko wykrywać sytuację gdy
- głębia jest niepoprawna (dałoby się zrobić atomowo na u64?)

Tworzylibyśmy warstwy bezpośrednio do przetworzenia dla rasteryzera, w takiej sytuacji każda
warstwa mołgaby mieć inną reprezentację? (reprezentacje musiałyby być takie same w ramach 8x8)

Problem: indeksy trójkątów. Dla każdej warstwy mamy inny zestaw indeksów trójkątów?
  - offset do indeksów, ilość trójkątów, ilość bitów na indeks w masce.
Problem: kto ładuje które trójkąty?

Problem: co jeśli mamy 64 trójkąty w masce?
  - zależnie od ilości tróəkątów rózne strategie? musiałyby być wspólne dla bloku 8x8!
  - poza tym, co jak mam 4 trójkąty? 28 wątków czeka?

Dobrze by było żebyśmy mogli współdzielić tróəkąty między warstwami. Mielibyśmy dwa strumienie:
- strumień trójkątów, i strumień warstw.
W każdym kroku dochodzi trochę nowych trójkątów a trochę wypada.
Indeksy w warstwie mapują się na tróəkąty z drugiego strumienia.

Jest jakiś limit trójkątów w SMEM. Pewnie więcej niż 48 / 64 wątki nie zmieszczę...

Problem: jak generować takie strumienie?



Może najlepiej by było jakby wątek który ładuje trójkąta zajmował się też renderingiem jego
pikseli? SMEM by było użyte do trzymania framebuffera.
- jeśli mielibyśmy dane posortowane per pixel, podzielone na warstwy i równomiernie rozłożone
- w paczkach.
- moglibyśmy trzymać 4 piksele na wątek (głębię + kolor)

To też jest słabo, bo często się zdarza, że cały blok (16 pikseli) jest wypełniony  jednym
trójkątem. W takiej sytuacji 4 razy bym ładował dany trójkąt. A na jeszcze szerszy kontekst
mnie nie stać (16 pikseli na wątek).



Czy da się jakoś zrobić mechanizm synchronizacji sampli z różnich warstw generowanych przez
różne wątki?

Np. mam grupę 4x4 piksele. Zaalokowałem do niej 8 wątków. 4 wątki pracują na warstwie 0, 4 na
warstwie 1. 
Czy na róznych warstwach powinny pracować różne warpy? Warstwa N może być zmergowana dopiero
jak warstwa N-1 jest zmergowana w całości. Tylko, że wątki zanim zmergują mają trzymać sample w
rejestrach?


To może inaczej:
- dane tróəkątów w SMEM. po jednym warpie na warstwę. Np. 512 wątków na blok 8x8. Od razu
  ładujemy wszystkie trójkąty.
  Generujemy sample (wątek w każdym warpie odpowiedzialny za max 2 piksele?). 
  Na końcu warpy w kolejności commitują wygenerowane sample do Framebuffera w SMEM.
  
  Dzięki temu, triangle setup robimy tylko raz na tróəkąt.
  Dobrze by było maksymalnie jak się da upakować warstwy.
  Problem: jak równomiernie rozkładać pracę nad pikselami między wątki?


Problem: jak dobrze zrobić algorytm generowania upakowanych warstw?
- jest to na pewno prostsze niż pełna rasteryzacja
- na inpucie mamy to co teraz generuje mask_raster, tylko posortowane?
  może być dużo pustych pikseli, chodzi o to żeby po nich nie iterować

mergowanie hierarchiczne?
- 

problemem aktualnie jest faza finalna i faza sortowania, na tych etapach raczej podział
trójkąty na duże/małe/particle nie ma sensu?


Jak zrobić warstwy?
Powiedzmy, że na razie chcemy jedynie przyspieszyć sortowanie i na razie robimy 4x4.
- w ramach warstwy znowu mamy sytuację gdy trójkąty mogą być duże lub małe; jak by były duże to
  możemy rozpatrywać same trójkąty
- mielibyśmy dwie ścieżki? jedna ścieżka dla małych meshletów i druga dla całych trójkątów?
  przed sortowaniem mergowalibyśmy je w jeden strumień
  jeden strumień czego?
  dla zwykłego trójkąta: 16-bit indeks w liście tile-i
  dla warstwy: indeks meshleta + 16 * 4 bity w każdym pikselu
    problem: taka reprezentacja w finalnym rasteryzerze jest taka sobie

  jeśli za dużo będę przechowywał per-piksel to może się bardziej opłacać po prostu przechować
  kolor + głębię (64-bity). Minus jest taki, że nie działa efekt mgły
  Jeśli za dużo danych przechowuję per trójkąt i mam średnio 1 trójkąt na piksel, to może się
  to bardziej opłacać...

  Teraz w przypadku masek mam 32-bity na maskę i mały indeks + 32-bity na indeks w tile-u +
  32-bity na indeks w binie...
  Choć to jest przypadek krańcowy... średnio tróəkąt ma pewnie z 2-3 piksele...


  Może mógłbym utrzymać założenie, że w jednym bloku jest jedna warstwa?
  jeśli dwie warstwy się ze sobą przecinają, to mógłbym jedną z nich rozbijać na dwie?
  Ale jak to dobrze robić?

  Obawiam się, że warstwy oparte o meshlety na końcu mi się nie przydadzą: W ramach bloku
  potrzebuję minimalnej listy tróəkątów które faktycznie występują na danym bloku

  jeśli byłbym w stanie podzielić tróəkąty w ramach tile-a na niezależne segmenty to mógłbym
  jakoś zawęzić liczbę tróəkątów?
  
  Tyle, że indeksy trzymam per- tile a nie per blok. Per blok byłoby więcej?
 
 
  Przy rasteryzacji chcę jak najszerszy kontekst? nie koniecznie, bo np. w hairballu max trisów
  na tile to > 64K...

  Problem z równoległym obliczaniem różnych warstw: nie mam dostępu do wartości piksela pod
  spodem...
  
  Tak naprawdę to ten efekt mgły jest dośc ograniczony, jeśli mam tylko wartość koloru. Może
  fajnie by było mieć indeks trójkąta np. ?

  Kompromis: 4 wątki na blok (każdy wątek obsługuje inny rząd)?
- Ale, żeby mieć 4 piksele na wątek, to muszę mieć post-sortowane warstwy!

  Jaka jest najsensowniejsza reprezentacja dla warstwy?


-----------------------------------------------------------------------------------------
                          === Problemy z aktualnym systemem ===
-----------------------------------------------------------------------------------------

* Rendering transparencji wymaga renderowania trójkątów w odpowiedniej kolejności; uniemożliwia
  to sortowania tróəkątów po materiałach i raczej wymaga stosowania uber-shadera

* Duże straty na wydajności przy rysowaniu sliverów (najlepiej widoczne na hairballu). Wynika
  to przede wszystkim z tego, że faktyczną rasteryzcję wykonuję dopiero na etapie bloków,
  wcześniej (na etapie binów i tile-i) używam jedynie AABB.

* Filtrowanie głębokości wymaga skwantyzowania koloru do 8-bitów na komponent. Może to
  powodować problemy i prawdopodobnie muszę w takiej sytuacji robić za każdym razem konwersję
  do/z sRGB. Ew. mógłbym przeznaczyć więcej bitów na kolory (10/11) a wartość alpha trzymać
  razem z głębokością (zmniejszoną do 24 bitów).

* Kafle mogą aktualnie obsłużyć max 64K trójkąty; Na niektórych scenach to za mało (San Miguel)
  Dodatkowo nie obsługujemy na razie kafli gdzie ilość trójkątów w blokach jest większa niż 2K.

* Główne etapy pipeline-u są cału czas zbyt wolne:
  - generowanie masek
  - sortowanie masek
  - finalna rasteryzacja

* *Podstawowy problem: przechowywanie danych trójkątów w SMEM*
  Generalnie jeden wątek operuje na 1 trójkącie, a 1 tróəkąt wymaga dużo danych!
  Jeśli dałoby się obliczenia wykonywać na 16-bitach, to by nie było problemów?
  Ale raczej się nie da...


* *Mam limit na trójkąty per tile: 64K; ale na hairballu jest przekraczany...*

-----------------------------------------------------------------------------------------
                 === Potencjalne rozwiązania / ulepszenia algorytmu ===
-----------------------------------------------------------------------------------------

* *Dodać opcję wizualizacji głębokości do głównego menu (bez rekompilacji)*

* *Bucketowanie trójkątów w tile-ach po ilości rzędów*
  Najlepiej by było brać pod uwagę wygenerowane maski, ale nie mamy ich na etapie estymacji
  Na etapie estymacji mamy jedynie wymiary quadów w tile-ach. Możemy zrobić 4 albo 16 bucketów.
  To powinno poprawić dystrybucję trójkątów na etapie 
  Problem jest taki, że nie jestem w stanie z wyprzedzeniem wyliczyć ile trójkątów będzie w
  każdym z bucketów, bo niektóre mogą być zcullowane.

* *4x4 może sie okazać zbyt kosztowne* Może zrobić tylko opcję 8x8?

* *Nowy algorytm rasteryzacji finalnej*
  - alokujemy 64 wątki na kafel; W danym momencie mogą przetwarzać max 64 piksele na raz
  - wątek jak przetwarza piksel to robi to od początku do końca, ale jak skończy to może
	przejść do następnego
  - ładujemy na początek tróəkąty z max 4 bloków do 4 różnych slotów. W momencie w jakim
	załadowaliśmy już wszystkie trójkąty dla danego bloku i jakieś tróəkąty zostały
	przetworzone, możemy ładować tróəkąty z kolejnego, jeszcze nie przetwarzanego bloku.
	W efekcie w danym slocie w danym momencie mogą być tróəkąty z 2 różnych bloków.
	Dla każdego bloku śledzimy:
	- ilość całkowicie przetworzonych trójkątów
	- ilość załadowanych tróəkątów
	- wskaźnik na najwcześniej załadowany trójkąt; w momencie w jakim trójkąt jest przetworzony
	  ten wskaźnik się przesuwa do przodu i zwalnia miejsce na tróəkąty dla kolejnego bloku
  Problem: efektywna implementacja

* *Encodowanie danych trójkąta?*
  - wektory normalne można zakodować jako 1 liczba 32-bitowa
    ale z długościami już by było gorzej
    Czyli teoretycznie wektor możemy zakodować w 64-bitach zamiast w 96?
    Całkiem dobrze można zakodować normalną w 32 bitach (metoda hemi oct)
    tri0: 3xf32, edge0: f32+u32, edge1: f32+u32 (7 liczb i tak...)

* *Lepszy load balancing*
  - W różnych fazach możemy po załadowaniu trójkątów jakoś je pogrupować, żeby zmniejszyć
    rozbierzność w ramach wątków
  - W niektórych fazach zmiana ilości wątków w grupie mocno wpływa na wydajność w danej scenie.
	Dla różnych scen różne wartości sa optymalne. Może dałoby się tak przerobić te algorytmy,
	żeby się w jakiś sposób same dopasowywały do danych?
	Np. tile dispatcher mógłby operować na więcej niż jednym binie na raz? Albo alternatywnie
	moglibyśmy mieć kilka tile-dispatcherów gdzie każdy ma inną ilość wątków w grupie i każdy
	by odpowiadał za biny o różnych ilościach tróəkątów.
  
* *Lepszy sposób zapisania danych warstwowych per-blok*
  Zamiast bit-masek dla każdego trójkąta moglibyśmy mieć:
  tablicę 4/6/8 bitowych indeksów + listę trójkątów
  Na hairballu to mogłoby dać duży zysk, ale  drugiej strony na sponzie nie bardzo...

* *Zamiast masek bitowych zapisujmy zakresy pikseli*
  - przeliczanie centroid: może da się szybciej
  - przerobić mask_raster: to chyba wymaga precompute-owanych normalnych...

* *Rendering niektórych binów w blokach 8x8 a nie 4x4*
  - każdy bin musiałby byc oznaczony jako 4x4 albo 8x8. Na razie chyba po prostu po ilości
	trójkątów? później jak dodamy specjalny path dla małych trójkątów, to ich ilość może
	bardziej wpływać na wybranie wersji 4x4 niż 8x8
  - możliwe też, że jeśli wersja 8x8 będzie dużo szybsza to wogóle zrezygnujemy z 4x4
 
  - nowy tile dispatcher: zaczyna z listą trójkątów w binie i generuje listy dla każdego
	sub-tile-a (8x8). Każdy sub-tile testujemy trivial rejectem & acceptem.
  - nowy mask raster: przechodzimy po listach i generujemy maski 8x8
  - nowy mask sorter: sortujemy każdą grupę niezależnie?
  - nowy tile_dispatcher: 
  To by wymagało:
  - nowa faza tile_dispatchera: od razu byśmy dispatchowali do sub-tile-i 8x8
  - nowa faza mask_rastera:     

* *Przyspieszenie sortowania*
  - może nie ma sensu sortować wszystkich bloków w tile-u razem? Lepiej chyba niezależnie?
  - razem ma sens jeśli liczba t©ójkątów jest naprawdę mała
  - Wersje sortera:
    <= 256  tri-bloków / kafel: sortujemy wszystkie razem
    <= 1024 tri-bloków / kafel: sortujemy wszystkie razem
	mask_raster od razu może posortować wg. bloków jeśli wszystkie się mieszczą w SMEM
	jeśli używamy scratcha to zawsze sortujemy każdy blok niezależnie
  - Alternatywnie te trójkąty moglibyśmy od razu posortować w mask_rasterze. I tak nie używamy
	w nim SMEMu.

	<=   64 tri / blok
	<=  256 tri / blok
	<= 1024 tri / blok
	>  1024 tri / blok
	Ale musielibyśmy też mieć bardzo szybką metodę iterowania po binach i ich kaflach

  Jak już zrobimy różne wersje, to można się pokusić o przyspieszenie na NVIDII za pomocą
  shuffli.

* *Finalny raster: Precompute-owanie danych dla trójkątów w ramach bloków w SMEM*
  Może dałoby się trzymać więcej danych, jeśli byśmy byli w stanie jakoś
  cache-ować wierzchołki?
  
  Specjalna obsługa tróəkątów które zajmują cały quad 4x4? W przypadku 4x4 jest ciężko, łatwiej
  by było to zrobić przy 8x8, bo wtedy robimy dla całego warpa.
  Moglibyśmy zrobić dwa rodzaje binów: w jednych operowalibyśmy na blokach 4x4 a w drugich na
  sub-tile-ach 8x8. Ale na jakiej podstawie stwierdzić która strategia jest lepsza w danym
  binie?
  Tam gdzie mielibyśmy odpowiednio gęstą geometrię byśmy szli 4x4. Bierzemy pod uwagę: ilość
  trójkątów, średnia wielkość tróəkąta i jego 'sliverowatość'. Ważne jest też czy tróəkąty są
  'skupione' czy rozrzucone, a właściwie, jak bardzo się przecinają. Ale tego się nie da szybko
  zmierzyć?
  
  Stosunek ilości trisów/blok do unikalnych trisów/tile:
  Dragon:1.07, SanMiguel:1.8, Sponza:4, Powerpl:2, Teapot:3, Hairball:1.5 Gallery:1.3 Conf:4
  
  Czy da się jakoś lepiej ładować tróəkąty? może jakoś zahashować? Ale co w wypadku kolizji?
  Ładować różne ilości masek, zależnie od tego, ile tróəkątów się mieści w buforze?

  Problem: nawet na Sponzie średnia ilość pikseli w masce to 10/16. Jeśli przyspieszymy 2x
  poprzez rysowanie wszystkich pikseli w ramach bloku dla danego trójkąta to stracimy prawie
  całe przyspieszenie przez rysowanie pikseli które są wyłączone.
  
  A co można zrobić ze scenami typu hairball? Jeszcze większy podział (2x2)? I przetwarzanie
  list 2x2 jedna za drugą. W tile-u mielibyśmy ich 64. Możemy przydzielić 32 wątki na kafel?
  Przy czym, po skończeniu każdego kawałka 2x2 od razu go zapisujemy do pamięci. Dzięki temu
  nie musimy trzymać w pamięci wszystkich pikseli, ale możemy lepiej zbalansować obliczenia?
  Grunt, żeby po jednej fazie cieniowania można było się szybko przełączyć na inną grupę 2x2.


* *Optymalizacja ładowania danych trójkątów do wczesnej rasteryzacji*
  - Współrzędne wierzchołków NDC można zapisać z 8-bitową sub-pixelową precyzją w 4 uintach
	(dla małych trójkątów mniej). To wszystko co potrzebujemy do rasteryzacji za pomocą
	algorytmu bazującego na liniach.
  - Do generowania głębokości wystarczy wektor normalny + plane_dist. To można zapisać w 3
	floatach.
  Obydwie te rzeczy można by precompute-ować w trans_setup: zapisanie 4 floatów/trójkąt zajmuje
  ok. 700msec na power plancie, 200msec na san miguel.
  
  W końcowej rasteryzacji te dane raczej się nie przydadzą, bo do wyznaczenia współrzędnych
  barycentrycznych potrzebujemy pełną informację o tróəkącie (minimum 9 liczb). Dałoby się
  wyliczyć z wierzchołków NDC i płaszczyzny wektory do wyznaczania barycentryków, ale to jest
  raczej niepotrzebne zawracanie dupy (szybciej będzie po prostu wczytać pozycje wierzchołków).

* *Przetwarzanie małych (max 8x8 pikseli) i dużych trójkątów niezależnie*
  - Dla małych trójkątów możemy w jednym kroku wyznaczyć maskę, a nie w każdym kaflu w jakim
	występuje. Moglibyśmy takie t©óəkąty binować wg. ilości zajmowanych rzędów, dzięki temu
	można by te maski bardzo wydajnie generować.
  - Dla dużych trójkątów dużo bardziej opłaca się sprawdzanie czy przecinają się z binem czy
	tile-em. W niektórych scenach wykonywanie takich testów powinno dać duży zysk (hairball).
	Jeśli wydzielimy małe tróəkąty to strata na pozostałych scenach powinna być bardzo mała (bo
	głównie dla małych tróəkątów ten test jest mało przydatny).
  - Problemem może być wyznaczanie wartości głębokości. Jeśli wyznaczę jedną wartość dla całego
	tróəkąta, to może to generować dużo niepoprawnych pikseli. Może jestem w stanie łatwo
	zidentyfikować takie problematyczne trójkąty? Po wektorze normalnym? Jeśli tróəkąt jest
	prawie prostopadły do promienia to będzie powodować problemy...

* *Optymalizacja trans_setup*
  Powinniśmy generować listę widocznych trójkątów; Setup po wstępnym przetworzeniu tróəkątów
  zapisuje dane / indeksy do SMEM i w kolejnej fazie kontunuuje przetwarzanie tylko na
  widocznych trójkątach/quadach.
  Problem: dane trójkątów nie mają szans zmieścić się w SMEM...

* *Przyspieszyć mip-mapping*
  - na razie w każdym pikselu efektywnie liczymy 3x zinterpolowane współrzędne UV i liczymy
	różnicę. Może dałoby się to zrobić jakoś szybciej? Np. wymuszając rendering w grupach 2x2?
	Coś mi się zdaje że będzie wolniej...

* *Meshlety*
  Oprócze tego, że zwiększyły by lokalność danych to moglibyśmy dzięki nim zrobić efektywnie
  precompute-owane dane.
  W meshletach oprócz wierzchołków i tróəkątów moglibyśmy też mieć krawędzie, które moglibyśmy
  precompute-ować (dla całego meshleta). Krawędzie byłyby współdzielone między trójkątami więc
  musielibyśmy wziąć pod uwagę kwestię kierunku.

* *Szybsze obliczanie małych sum prefiksowych*

* *Bug jeśli dwie powierzchnie na siebie prawie nachodzą (jedna backface)*
  szczególnie widoczne na sponzie

* *Bugi na Haswellu pojawiające się gdy jest za mała liczba wątków w mask_raster*

* *Bugi widoczne w różnych miejscach na powerplant jak się wyłączy backfaceculling*
  Czasami też widać miganie na rurach (pewnie są identyczne wartości głębi)

* Lepsze cache-owanie danych wierzchołków w finalnym rasterze? Ale jak to zrobić sensownie...

* Lepsza kolejność danych wejściowych: może to mocno wpływać na wydajność początkowych etapów
  pipeline-a (setup & binning).

* *Czy bardziej się opłaca rasteryzacja 3D czy 2D?*
  - w 2D musielibyśmy przechować pozycje wierzchołków i je poprzycinać;
    ale za to rasteryzacja byłaby prostsza? tak samo jak wyznaczanie bboxa dla trójkątów
	przyciętych w ramach kafla.

* *Option not to run checks every frame*

-----------------------------------------------------------------------------------------
                       === Dodatkowe ulepszenia aplikacji ===
-----------------------------------------------------------------------------------------

* Wymyślić jakąś nazwę dla algorytmu. Np. CBTR ? compute-based transparent rasterization ?

* Zaimplementować MSAA, zobaczyć czy tile-renderer ma przewagę nad hardwarem w tym zakresie.

* Dodać jakąś prostą animaowaną scenę? animowane boxy?

* Dodać możliwość renderingu obiektów nie-przezroczystych normalnie a jedynie przezroczystych
  za pomocą trans-renderera. To wymaga dodania obsługi czytania z bufora głębokości.

* Dodać weighted-blended OIT, żeby mieć porównanie z faktycznie stosowanym algorytmem?

* Dodać obsługę renderingu dwu-fazowego transparencji (od Wolfire):
  - materiały bez alphy najpierw, te z alphą potem
  - opcja: alpha test na 100% najpierw
  - sposób blendowania: normalny albo addytywny
    można tej metody użyć też razem z trans rendererem!

* Obsługa kamery orbitującej jest do D; dać możliwość focusowania się na klikniętym elemencie?

* Modyfikacja kawałków shaderów nie powoduje reloadu

* Rendering pół na pól (simple po lewej / trans po prawej).

----------------------------------------------------------------------------------------
                                    === Tri patche ===
-----------------------------------------------------------------------------------------

Dałoby się zrobić część meshy na quadach a część na tróəkątach?
Problemz ogólnym systemem: instancing...: dla każdej instancji muszę
przekształcić wierzchołki i je gdzieś zapisać, inaczej musiałbym to robić 2 razy:
- przy wyliczaniu AABB i podczas rasteryzacji (słabe); OK! akceptujemy to!

dobra, powiedzmy ze da się w miarę sensownie przerobić mesh bazujący na tróəkątach na quadowy.
Co dalej?
Grupować quady w czwórki ? Tylko takie które współdzielą wierzchołki?

Przy czym grupowanie w czwórki powinno być maksymalnie szybkim algorytmem. 
To czemu od razu nie robić ray-tracingu ? Może ne wszystko na raz

Ale Do grupowania obiektów mógłbym użyć grida albo BVH czy coś podobnego?
Musi to być szybkie. Przy czym mi zależy na tym, żeby przyspieszyć etap
rasteryzacji kafli i bloków. Jak zrobie quady, to pozostałe etapy powinny być wystarczająco
szybkie.

Grupowanie quadów w czwórki pomoże? Potencjalne problemy:
- więcej trójkątów do przetworzenia na poziomie tile-a?


Podobny algorytm można zrobić do generowania czwórek. Ale tutaj straty na pewno będą większe.
Co w takich sytuacjach? Czwórki będziemy rozpakowywać na poziomie tile-a?

Tak czy inaczej: najpierw powinniśmy zrobić same quady, jeśli przyspieszą to wtedy pomyślimy od
rozszerzeniu

Jaka byłaby reprezentacja takiej czwórki?
- 9 indeksów wierzchołków ?
- a co zrobić ze ścinkami?

Może coś prostszego: jakoś uporządkować quady? ale jak to zrobić szybko?
grupujemy jedynie quady które są faktycznie blisko siebie? Ale co będziemy robili z
nie=pełnymi grupami? Będą nam psuć occupancy!


A może dużo większe meshlety ? 256 wierzchołków i 512 trójkątów ?

32 wierzchołki: wystarczy 15 bitów na trójkąt


Generacja:
- ciągłość powierzchni nie jest taka ważna jak lokalność w przestrzeni?
- np. hairball: nie ma sensu lecieć po włosach, lepiej robić wycinki lokalnej przestrzeni

- do pewnego stopnia na pewno chcemy łapać trójkąty które są ciągłe
  A może: olać ciągłość, wybierać wierzchołki w pierwszej kolejności?


- Niezależnie trzymamy dane indeksów i wierzchołków ?
- Jakie limity ?

- Czy mogę zapewnić, że paczki wierzchołków/trójkątów będą wypełnione po brzegi?
- stosunek num_tris/num_verts wacha się od 0.8 do 2.1; Generalnie tróəkątów jest tyle co
  wierzchołków, a w niektórych meshach nawet 2x tyle


- Póżniej mozemy zdecydowac czy dopychamy trojkaty czy wierzcholki

- Na początek robimy to statycznie:
  - mamy listę instancji, każda instancja ma odnośnik do paczki trójkątów i jej wielkość?
    najprościej żeby paczki trójkątów miały takie same wielkości
    Może się okazać, że marnujemy pamięć, bo albo w buforze wierzchołków albo w buf. trójkątów
	będzie trochę zmarnowanego miejsca;
	Lepiej marnowac miejsce w buforze tróəkątów?

    - paczki po 64 wierzchołki; Instancja może mieć odnośnik do max 4 paczek (wierzchołki 0-63,
	  64-127, 128-191, 192-255).
	- Trójkątów ładujemy od razu 256?

	- Ilośc wierzchołków ustalamy na wartośc stałą a t©óəkątów na zmmienną?
	  Czy jest sens mieć więcej niż 256 tróəkątów?

	Czy mogę założyć, że w trans_setup będę miał więcej niż 1 meshlet?
  - Np. jeśli jeden się nie zmieścił to dopycham drugim?

	Wierzchołki:
	128 * float = 42 * float3 (position, normals, uvs + colors)
    256 * float = 85 * float3

	Trójkąty:
	64 * uint  = 85 trójkątów
    128 * uint = 170 trójkątów
  - 7 bitów na indeks: 64-bity = 3 trójkąty: 128 * uint = 192 trójkąty

	ChunkMeshInstance {
		u8 num_tris, num_verts;
		u16 flags; // has_uvs?, has_normals?, etc.
	    u32 verts_offset, uvs_offset, normals_offset;
  	 	u32 tris_offset;
		// Do tego: bounding boxy, zakresy normalnych (do szybkiego backface-cullingu)
  	 	// Parametry materiałów; Na razie po prostu jeden materiał na 1 chunk
	};

	Instancja: ~128 bajtów
	Tróəkąty:   512 bajtów
	Pozycje wierzchołków: 1024 bajty 
	UVki + kolory:        1024 bajty
	normalne:             1024 bajty

*Co trzeba zrobic?*
- wygenerować w miarę dobrze upakowane tri patche
- na razie olewamy bboxy? tak, żeby można było zrobić w miarę sprawiedliwe porównanie z podstawowym renderingiem
- skopiować TriPatche do pamięci GPU
- Przerobić tri_setup: dane wierzchołków (co najmniej pozycje) trzymamy w SMEM?
- Problem: gdzie trzymamy dane przycętych wierzchołków? Normalnie np. UVki wogóle nie są
  modyfikowane; Wraca dylemat: rastaryzacja 2D czy 3D ?
  Bez sensu przepisywać cały bufor jeśli zmienił się jeden wierzchołek
- W headerze trzymamy offset do bufora clipowanych wierzchołków; Najwyższy bit w wierzchołku
  oznacza, że jest clipnięty i tyle
- Inna numeracja trójkątów /  wierzchołków: Dla danego t©óəkąta mamy indeks paczki który
  identyfikuje od razu zestaw wierzchołków? A UVki i normalne?


Na początek najprostszy sposób:
- cała scena ma jeden rodzaj wierzchołka?  Jeśli byłyby różne typy, to w raster musiałbym mieć
  cache na instancje? Każdy dostęp do trójkąta wymaga odwołania do danych instancji?

  Chyba, że dane wierzchołków różnych typów byśmy trzymali w jednym buforze i po prostu miałyby
  rózne zakresy?

  Jak tróəkąt jest zapisany na liście w tile-u? 24-bit: indeks instancji + 8-bitów na indeks trójkąta?
  Na początek tak.

  Tile dispatch zajmuje dużo czasu, czy dałoby się to jakoś przyspieszyć? Przy pierwszym
  binowaniu możemy operować na instancjach (ew. z mapą bitową trójkątów). Powinno się dać coś
  przyspieszyć Np. jeśli dałoby się operować na grupkach (2-8) tróəkątów a nie całych tróəkątach
  to już moglibyśmy mieć duży zysk na tym etapie
  
Jak duże powinny być TriPatche? 
- na tyle duże, żeby wypełnić warp
- jak duże będą za duże? raczej na pewno będą za duże, żeby założyć, że większość trójkątów
  wypełnia kafel 16^2
  
--- *Cieniowanie* ---
- musimy przekazywać jakoś wektory normalne; Jak to robić najlepiej ?
  raczej nie ma sensu pakować wszystkiego do TriangleData. W triangle data zostawiamy indeksy
  wierzchołków, które są w jednym buforze wierzchołków
  Jak je indeksować ? 

  informacje jakie musimy mieć:
  - lista instancji: każda instancja ma indeks mesha, materiał, macierz, etc.
  - lista wierzchołków wejściowych;

  Problem: dane wierzchołków trzymamy w jednym dużym buforze? Oddzielne bufory na oddzielne
  atrybuty; każda instancja może mieć offset na globalny bufor wierchołków, normalnych,
  indeksów trójkątów, etc. ?

  W Trans nie muszę robić nic wyszukanego: mogę użyć alokatora BestFit


  - nie robimy żadnego cullingu, tak żeby porównanie było sensowne
  musimy je jakoś generować dynamicznie:

  Obsługujemy wiele różnego rodzaju draw-calli:
  - statyczna / dynamiczna geometria
  - z instancingiem lub bez
    indeksowanie vertexów w statycznych meshach to raczej nie problem?
	ale co ze skinned meshami ? każda instancja może też być inaczej przekształcona...
	Dodatkowo, aby wyznaczyć AABB tróəkątów i Z min/max, muszę mieć dostęp do przekształconych
	wierzchołków...
	W compute chyba ciężko będzie to zrobić lepiej niż w geometry shaderze ?
  - najgorsze, że dostępy do VBuffera mogą być dalekie od ideału. w standarodwym pipelinie mamy
    pewnie jakiś cache...
	
    Pewnie łatwiej by było jakbyśmy mieli TriPatche / meshlety; Tak czy inaczej to jest ew. na potem
    Czy meshlety działałyby też z instancjami/skinned meshami ? 

    Vertex shader przekształcał by cały meshlet? moglibyśmy też podzielić meshlet na 2 cześci:
	dane trójkątów i dane wierzchołków; jeśli robiłbym na meshletach, to 
    Czy jest sens od razu robić meshlety ?

    Czy meshlety mogą mi też pomóc z transparencją? Jeśli miałbym tam informacje o warstwach to
	mógłoby to uprościć sortowanie? Ale jak konkretnie? per pixel i tak przetwazam poszczegolne
	trojkaty? a moze po prostu przetwazalbym (i sortował) tri-patche? ok, ale co jeśli tri
	patche będą się przecinać? w takiej sytuacji lepsze byłoby sortowanie trójkątów...
	A jak już mam listę tróəkątów, to fakt, że 2 trisy są z tego samego patcha nic mi nie daje?

    Patche na pewno będą musiały być dzielone na nie-overlapujące kawałki do sortowania
  
  - Teoretycznie przekazywanie patchy aż do poziomu kafli mocno przyspieszy binowanie, ale na
	poziomie kafla może to mocno zwiększyć bandwidth? A może nie koniecznie? jeśli dałoby się
	nie ładować np. od razu całych danych wierzchołków? ale to chyba nie ma sensu?
  - Bardzo dużo zależy od tego: ile patchy średnio byśmy mieli per bin/tile/block

  - Jeśli np. w prakty tile pokrywał np. 20% lub mniej powierzchni patcha, to byłoby bardzo
	słabo...
	
  - Dodatkowy problem z tripatchami: mozna je tylko renderowac w calosci, czy moze być opcja
	renderingu zakresu tróəkątów? nie ma problemu z zakresem, będzie to zwykla maska
	trzeba bedzie troche wysilku wlozyc w przerobienie scen, tak, żeby materialy się cały czas
	poprawnie mapowaly na trojkąty
	
   - to się wydaje proste ale pewnie będzie 1-2 tyg roboty...

  Chyba lepiej najpierw zrobić prostszą metodę tak czy inaczej; CHoćby po to, żeby mozna było
  faktycznie porównac?
	
W tym problemie ważne jest chyba jak najlepsze skompresowanie danych?
  - *Problem:* to jest bardziej skomplikowane i tak naprawde nie potrzebuje tego do gry; Moze
	na początek i tak lepiej jest zrobić coś prosztszego?
	
	Ale czy da się sensownie zrobić ten renderer z normalnymi vertex & index bufferami ? tzn.
	lepiej niz geometry shader?
  - Najważniejsze: jak łączyć dane wierzchołków z trójkątami ?

  Zainstaluj Visual Studio zeby latwiej debugować ?
 
*Potencjalne rozwiązania:*
1. - TriPatche ? A co z partiklami ?
2. Jakaś detekcja warstw trójkątów ? To wszystko może być bardziej kosztowne niż zwykłe OIT...
3. Czy dałoby się szybko wykrywać nie overlapujące warstwy trójkątów dla danego rzutu ?
  dla zwykłych meshy może dałoby się coś pokombinować, ale co zrobić z partiklami ?
  albo po prostu z chmurami tróəkątów ?
  podział na warstwy po głębokości ? każdy trójkąt ma jakiś zakres głębokości (min/max po zrzutowaniu)
  można tego użyć to pokubełkowania całej geometrii;
  zostało by nam na koniec tylko sortowanie w ramach warstw.
  OK, ale warstwy mogą się overlapować; niektóre tróəkąty występowałyby w wielu warstwach ?
  jeśli warstwy byłyby w ramach binów to może dałoby się sensownie porozdzielać geometrię ?
  Ale jak dobrze wyznaczyć zakresy warstw? musi to się jakoś pokrywać z faktycznym rozkładem
  głębokości w trójkątach;
  Czy podział na warstwy zawsze jest możliwy ? Żeby było bezpiecznie, przy wybieraniu trójkątów
  muszę zawsze wybrać wszystkie które overlapują po Z; Mogą być takie sceny pewnie gdzie jest
  tylko jedna warstwa zawierająca wszystkie trójkąty
  Np. jeśli mamy na scenie duże trójkąty otaczające całą scenę, to jeden taki może 'przykleić'
  do siebie wszystkie pozostałe...

  *Może takie trójkąty wrzucajmy wiele razy z różnymi zakresami głębokości ?*
  Ale:
  - chciałbym minimalizować takie trójkąty
  - warto byłoby jakoś zwizualizować sobie przecięcia scen o głębokości
    (histogramy dla różnych binów)
  Pod problem: jak dobrze wyznaczyć zakres głębokości trójkąta przyciętego do bina?
    bin może mocno ograniczyć ten zakres...
    na Hairballu to zmniejsza ilość trójkątów o ok. 2%; Na niektórych scenach może będzie
	więcej...

  Pod problem: rozkłady trójkątów na osi Z mogą być bardzo nierównomierne... co z tym zrobić?
  Chyba muszę z grubsza posortować po głębokości w ramach bina ?
  Ale sortowanie jest kosztowne...
  Zamiast sortowania binning na 256 kubełków?
  możemy zrobić symulację ile faz byłoby potrzebne, żeby przetworzyć dany bin

  Zaczynanie renderingu z poziomu bina to często za dużo; W niektórych sytuacjach lepiej jest
  robić rendering dopiero na poziomie kafli; Można to zrobić na 2 sposoby:
  - generować listy trójkątów dla poszczególnych kafli tak samo jak dla binów i zapisywać je
    do pamięci
  - robić rendering z poziomu bina  i w pętli filtrować t©óəkąty dla kafli; Problem: zakresy
    głębokości byłyby niedostosowane do konkretnych kafli?
